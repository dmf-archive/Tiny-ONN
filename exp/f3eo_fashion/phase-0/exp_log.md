# Phase-0: Architecture Comparison Log

## Standard ViT

**Model**: `standard`
**Epochs**: 12
**Status**: ✅ Completed

| Epoch | Train Loss | Val Loss | Train Acc | Val Acc |
|-------|------------|----------|-----------|---------|
| 1     | 1.2958     | 0.7184   | 51.68%    | 73.09%  |
| 2     | 0.6554     | 0.5481   | 76.27%    | 80.01%  |
| 3     | 0.5331     | 0.5325   | 80.74%    | 81.00%  |
| 4     | 0.4877     | 0.4554   | 82.04%    | 82.96%  |
| 5     | 0.4599     | 0.4488   | 83.15%    | 83.25%  |
| 6     | 0.4364     | 0.4158   | 83.91%    | 84.68%  |
| 7     | 0.4171     | 0.4073   | 84.70%    | 85.14%  |
| 8     | 0.4063     | 0.4104   | 85.21%    | 84.98%  |
| 9     | 0.3969     | 0.4214   | 85.32%    | 84.86%  |
| 10    | 0.3862     | 0.3904   | 85.70%    | 85.22%  |
| 11    | 0.3738     | 0.3910   | 86.08%    | 85.99%  |
| 12    | 0.3654     | 0.3937   | 86.46%    | 85.88%  |

**Final Val Acc**: 85.88%

---

## FFN-in-Head (SPL-style)

**Model**: `ffn_in_head`
**Epochs**: 5 (early stop, plateau)
**Status**: ❌ Underperforming

| Epoch | Train Loss | Val Loss | Train Acc | Val Acc |
|-------|------------|----------|-----------|---------|
| 1     | 1.3732     | 0.8453   | 47.48%    | 67.08%  |
| 2     | 0.7732     | 0.7673   | 71.87%    | 71.45%  |
| 3     | 0.8167     | 0.8114   | 70.60%    | 69.29%  |
| 4     | 0.7940     | 0.7144   | 70.67%    | 73.01%  |
| 5     | 0.7804     | 0.7742   | 71.11%    | 72.63%  |

**观察**：
移除专用的前馈网络（FFN）块并将其功能嵌入到注意力头中（SPL 风格）会**严重降低**模型容量。
这表明**FFN 块并非可有可无**，对于此任务的有效表征学习至关重要。

**启示**：
SPL 架构（当前实现）对于需要强大非线性变换能力的任务可能**存在固有缺陷**。
这种性能不佳**并非**由于优化顺序（F3EO 与 AdamW），而是由于**架构缺陷**。

**下一步**：
**仅在标准 ViT 上**进行 **F3EO 优化器**实验，该模型已证明其容量。
除非进行架构改进，否则我们**不会**进一步研究 FFN-in-Head。
