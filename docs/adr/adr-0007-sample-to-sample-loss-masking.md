---
title: "ADR-0007: 样本对样本损失掩码：从测试集预测到规则推断"
status: "Accepted"
date: "2025-10-07"
authors: "Ω Researcher, Tiny-ONN 课题组"
tags:
  [
    "architecture",
    "decision",
    "training",
    "loss-function",
    "rule-induction",
    "meta-learning",
  ]
supersedes: ""
superseded_by: ""
---

# ADR-0007: 样本对样本损失掩码：从测试集预测到规则推断

## 状态 (Status)

Proposed | **Accepted** | Rejected | Superseded | Deprecated

## 背景 (Context)

在解决了路由稀疏性和元学习信号问题后，我们意识到当前训练范式的根本缺陷可能不在于模型架构，而在于**损失函数本身**。

当前的损失掩码策略将模型训练为一个“上下文条件下的问答器（In-context Solver）”。它的任务是学习一个从 `test` 输入到 `test` 输出的映射 `f(test_input) -> test_output`，而 `train` 对仅仅是作为提示。这种范式隐含了一个危险的假设：模型应该像一个黑箱一样，从 `train` 对中**被动地**提取模式，然后应用于新输入。

然而，ARC 任务的本质并非简单的输入-输出映射，而是一个**规则推断（Rule Induction）**问题。模型必须从 `train` 对中**主动地**推断出底层的抽象规则 `R`，然后再将这个规则应用于 `test` 输入。当前的损失函数完全没有为“规则推断”这个核心过程提供任何监督信号。

## 决策 (Decision)

我们将训练范式从一个“仅预测测试集”的被动学习器，升级为一个“预测所有输出”的主动规则归纳器。

具体修改是在 `exp/arc/data.py` 的 `GridSerializer.serialize_task` 方法中，重构 `labels` 张量的构造逻辑。

**旧范式 (仅预测测试集)**:

- `labels` 中，所有 `train` 对的 `input` 和 `output` 部分，以及 `test` 的 `input` 部分，均被掩码为 `-100`。
- 模型仅对 `test` 的 `output` 部分计算损失。

**新范式 (样本对样本建模)**:

- `labels` 中，所有 `input` 网格（包括 `train` 和 `test` 的）以及所有结构性标记（如 `bos`, `im_start`, `im_end`）均被掩码为 `-100`。
- 模型必须预测**所有** `output` 网格的内容（包括 `train` 和 `test` 的），以及序列结束标记 `<|eos|>`。

**理论依据**:

1. **提供密集的监督信号**: 模型的每一次前向传播都会收到多个监督信号（每个 `train` 对一个），而不仅仅是一个。这极大地增加了学习信号的密度，可以加速收敛。
2. **强制进行元学习**: 通过要求模型解释 `train` 对，我们直接迫使它去学习 `train` 对之间共享的**抽象规则**。这不再是可选的上下文学习，而是成为损失函数强制要求的核心任务。模型必须找到一个能统一解释所有证据（`train` 对）的通用规则 `f`，这正是人类解决 ARC 任务的思维过程。
3. **样本对样本建模**: 这实现了真正的“样本对样本的建模”。模型不再是一个被动的模式匹配器，而是一个主动的、基于范例的推理引擎。

## 后果 (Consequences)

### 积极 (Positive)

- **POS-001**: **加速规则学习**: 为“规则推断”这一核心过程提供了直接的、密集的监督信号，预期将显著加速模型对抽象变换规则的学习。
- **POS-002**: **提升泛化能力**: 强制模型学习一个能统一解释所有 `train` 对的规则，这将直接提升其将该规则泛化到 `test` 输入的能力。
- **POS-003**: **理论自洽**: 使训练范式与 ARC 任务的“规则推断”本质重新对齐，消除了先前存在的理论矛盾。

### 消极 (Negative)

- **NEG-001**: **增加训练复杂性**: 引入了更多的监督目标，可能会使训练动态在初期变得更加复杂，需要仔细监控。
- **NEG-002**: **潜在的过拟合风险**: 要求模型完美地复现所有 `train` 对的输出，可能会使其过度拟合 `train` 对的特定细节，而忽略更普适的规则。然而，我们的动态稀疏路由和元学习机制（SARS）旨在通过学习**可复用的专家**来缓解这种风险。

## 考虑的备选方案 (Alternatives Considered)

### 方案 A: 维持现状 (仅预测测试集)

- **ALT-001**: **描述 (Description)**: 维持当前的“仅预测测试集”损失掩码策略。
- **ALT-002**: **拒绝理由 (Rejection Reason)**: 此方案存在根本性的理论缺陷，未能为“规则推断”提供监督，与 ARC 任务的本质相悖。它是一个次优的、被动的学习范式。

## 实施注意事项 (Implementation Notes)

- **IMP-001**: 实施集中在 `exp/arc/data.py` 的 `GridSerializer.serialize_task` 方法中，重构 `labels` 张量的构造逻辑。
- **IMP-002**: 此修改是一个纯软件层面的变更，无需改动模型架构，可以立即部署。
- **IMP-003**: 必须通过 `observer` 密切监控训练动态，特别是 `main_loss` 的收敛速度和最终性能，以验证新范式的有效性。

## 参考文献 (References)

- **REF-001**: `exp/arc/data.py` (新的损失掩码实现)
- **REF-003**: `docs/rules/DFC-Theory.md` (动态函数合成理论)
