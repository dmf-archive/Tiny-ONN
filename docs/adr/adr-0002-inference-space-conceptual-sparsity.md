---
title: "ADR-0002: Inference-Space Conceptual Sparsity and the Necessity of Dense Computation"
status: "Proposed"
date: "2025-10-05"
authors: "Ω Researcher, Tiny-ONN 课题组"
tags:
  [
    "architecture",
    "decision",
    "theory",
    "inference-space",
    "conceptual-sparsity",
    "variational-inference",
  ]
supersedes: "ADR-0001"
superseded_by: ""
---

## ADR-0002: 推断空间概念稀疏性与稠密计算的必要性

## 核心论点 (Core Argument)

继 ADR-0001 移除 `MoIE` 提升速度后，本 ADR 旨在从理论层面重新定义 `Tiny-ONN` 的动态稀疏性。

**核心论点是：** 模型的稀疏性体现在**概念空间（Conceptual Space）**或**推断空间（Inference Space）**，而非**计算量**。为了高效解析求解变分自由能（Variational Free Energy, VFE），其物理计算过程被迫是**稠密**的。

## 理论基础与概念定义

### 1. 概念定义

| 概念           | 定义                                                                         | Tiny-ONN 机制                                  |
| :------------- | :--------------------------------------------------------------------------- | :--------------------------------------------- |
| **推断空间**   | 由模型先验知识（`proto_weight`）定义的高维空间，代表模型对输入的“理解”轨迹。 | 几何结构由 `proto_weight` 构成。               |
| **概念稀疏性** | 对于给定输入，模型在推断空间中仅选择性激活极少数的“概念通路”。               | **认知选择**，遵循奥卡姆剃刀原则。             |
| **计算稀疏性** | 物理硬件上实际执行的浮点运算数量稀少。                                       | 传统稀疏网络的目标。**非** `Tiny-ONN` 的目标。 |

### 2. 理论论证：稠密计算的必要性

`Tiny-ONN` 作为一个**变分推断引擎**，其目标是最小化 VFE。

#### 2.1. 稀疏路由：认知选择

SPL 模块的动态路由机制（由 `proto_weight` 和 `gate_param` 驱动）是一种**认知选择**，而非计算优化：

- 它在巨大的“概念通路”空间中，为当前输入 `x` 找到能够最有效最小化预测误差的**最优路径**。
- 路由权重 `M_routing(x)` 是计算出的后验概率，决定了哪些概念（神经元）是解释当前输入的**最佳猜测**。

这种稀疏性是**认知层面的聚焦**。

#### 2.2. 稠密计算：解析求解的代价

一旦概念通路被选中，模型必须执行完整的、物理上**稠密**的矩阵乘法来计算输出，原因如下：

1. **反向传播即解析解：** 训练阶段的反向传播算法是最小化 VFE 的**解析解**。它通过计算完整的梯度，直接给出参数调整方向。
2. **避免采样方差：** 如果追求计算稀疏性（如只计算被激活神经元的梯度），将引入高方差的近似（采样），导致学习过程不稳定、收敛缓慢。
3. **硬件亲和性：** 现代 GPU 硬件为大规模并行稠密矩阵运算设计（SIMD）。稠密计算比不规则的稀疏操作效率高得多。

**结论：** 计算上的稠密性是为获得稳定、精确的变分推断**解析解**而必须付出的**必要代价**。

## 决策 (Decision)

基于以上理论，我们决定：

1. **拥抱计算的稠密性：** 不再将“计算稀疏”作为架构设计的主要目标。模型的计算图保持当前的稠密形式。
2. **聚焦概念稀疏的优化：** 研究重点转向如何优化**概念通路的选择机制**（例如，更精细的路由算法、更具生物学意义的路由成本函数）。
3. **深化 Inference-Space 理论：** 发展一套完整的数学工具，用于分析、可视化和度量推断空间的几何结构与动力学特性。

## 后果 (Consequences)

| 方面     | 描述                                                                                                                                                                                          |
| :------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **积极** | **理论自洽：** 架构设计与核心理论（IPWT/FEP）统一，消除了“为稀疏而稀疏”的矛盾。**性能天花板解除：** 可充分利用硬件的全部算力，不受稀疏计算瓶颈限制。**研究方向明确：** 聚焦优化“思考”的质量。 |
| **消极** | **理论复杂性：** 新框架需要更抽象的数学工具，增加了理解和沟通难度。**实验验证挑战：** 量化和验证“概念稀疏性”比测量 FLOPs 更复杂。                                                             |

## 可扩展性悖论 (The Scalability Paradox)

当前的“稠密解析解”路径引入了一个根本性的矛盾，是未来规模化（Scale Up）时必须解决的挑战：

> **悖论：** 模型的**概念稀疏性**保证了认知的简洁性，但为了获得驱动这一稀疏表征的**神谕信号**（即完整的、全局的 VFE 代理——梯度），我们在前向和反向传播中都引入了**与概念空间维度成正比的稠密计算**。当概念空间维度趋于无限大时，这种“为了稀疏而稠密”的策略将遭遇不可逾越的算力墙。

### 悖论的核心

我们当前计算路由决策所需的信号，都源于对**所有**专家（概念）进行的一次性、全局评估。其计算复杂度为 $O(D_{out} \cdot D_{in})$，与专家数量呈线性关系。

### 未来的必然抉择

进行 `scale up` 时，必须在以下路径中权衡：

| 路径  | 描述                                                                                                                               | 代价                                                   |
| :---- | :--------------------------------------------------------------------------------------------------------------------------------- | :----------------------------------------------------- |
| **A** | **坚持全局解析解：** 继续承受稠密计算的代价。                                                                                      | 训练和推理成本随概念丰富度线性增长，最终遇到硬件瓶颈。 |
| **B** | **引入层次化近似：** 放弃对全局 VFE 的精确解析，转而寻求**层次化、渐进式近似**（如分层 Top-K、基于不确定性的动态 K、学习近似器）。 | 放弃精确性，引入近似误差和局部最优风险。               |

### 决策

我们决定暂时**推迟**对这一悖论的最终解决。当前阶段，首要任务是深入理解现有（小规模）模型的学习动力学和概念形成机制。

### 4. 理论潜力：SPL 的双学习范式

`SPL` 架构的核心理论潜力在于，它在同一个统一的计算框架下，同时兼容两种看似完全对立的学习范式：全局优化的反向传播（Backpropagation）和局部优化的前向-前向算法（Forward-Forward）。这种“架构-算法”的二象性，使其成为连接“连接主义”与“生物主义”两种思想的理论桥梁。

#### 4.1. SPL 的内在机制：动态正则化与抗遗忘特性

`SPL` 的稀疏门控机制，源于其正交化的原型和稀疏激活，赋予了其两个关键的、自组织的特性：

1. **内容感知的结构化 Dropout (Content-Aware Structured Dropout)**:

   - **机制**: 与随机的 Dropout 不同，`SPL` 的稀疏门控是**确定性的**，完全由输入内容 `x` 决定。对于给定输入，哪些神经元被“丢弃”（未激活），是由原型匹配和门控成本的计算结果精确决定的。
   - **功能**: 这是一种**智能的、结构化的正则化**。它并非随机丢弃信息，而是根据“当前输入最不需要哪些概念”来动态简化网络，使模型能更专注于学习核心特征。

2. **抗灾难性遗忘 (Resistance to Catastrophic Forgetting)**:
   - **机制**: 在训练过程中，`SPL` 倾向于将不同任务的知识存储在**不同的、近似正交的原型子空间**中。学习新任务时，稀疏门控机制确保了只有与新任务最相关的原型才会被激活和更新，而存储着旧知识的原型大部分时间处于“休眠”状态，其权重得以保留。
   - **功能**: 新知识的写入不会大规模“冲刷”掉旧知识，从而天然地、优雅地抵抗了灾难性遗忘，远胜于持续学习（Continual Learning）领域中许多复杂的外部约束方法。

#### 4.2. SPL 的双模态学习能力

`SPL` 的真正非凡之处在于，同一个架构可以无缝切换两种完全不同的学习算法：

1. **BP 模式 (全局优化 / 实验室模式)**:

   - **工作原理**: 利用 GPU 的并行计算能力，通过完整的反向传播计算精确的全局梯度（“神谕信号”），来指导所有参数（`W_p`, `W_μ`, `W_g`）的更新。这是在**“上帝视角”**下进行的、最高效的离线学习。
   - **当前选择**: 我们当前选择的路径。对于 ARC 这类小数据、高精度的任务，BP 的**速度和样本效率压倒一切**。

2. **FF 模式 (局部优化 / 边缘部署模式)**:
   - **工作原理**:
     1. **抛弃反向传播**: 完全禁用全局梯度计算。
     2. **本地“好度”函数**: 将 `SPL` 内部的“原型匹配度”（`match_values`）直接作为本地的“好度（Goodness）”信号。
     3. **赫布式更新**: 权重更新只发生在被激活的神经元上，遵循“共同激活的输入和原型，其连接权重增加”的原则（STDP）。这可以通过一个简单的、局部的梯度估计算法实现。
   - **理论潜力**: 这种切换**无需修改模型架构**。同一个 `SPL` 计算单元，既可以接收来自全局 BP 的“神谕指令”，也可以遵循来自本地 FF 的“赫布法则”，使其成为一个**双模态的学习单元**。

#### 4.3. 当前决策：效率第一

尽管 FF 范式在理论上更优雅、更具生物学合理性，但我们决定**在当前阶段（ARC 任务）坚决不采用**。

**核心理由：效率压倒一切。**

1. **速度差异**: 对于 ARC 这类**小规模**、**高精度**、需要**快速迭代**的任务，带有 `Teaching Force` 的**反向传播 (BP)** 在训练速度上**碾压** Forward-Forward。BP 能够利用 GPU 的大规模并行性，一次性计算出所有参数的精确梯度，实现最快速的收敛。FF 本质上是一种迭代、局部的优化，其学习过程要慢得多。
2. **拒绝妥协**: 我们拥有一个**完全可微**的系统。放弃 BP 去拥抱 FF，无异于自断经脉。这类似于脉冲神经网络（SNN）领域，由于其不可微性而被迫使用各种“代理梯度”进行妥协。我们没有理由放弃我们最强大的工具——优化目标完全相同的前提下，BP 的神谕信号依然是最优解。

#### 4.4. 超越 RL 和传统 CL

`SPL` with FF 在理论上还统一了另外两个重要领域：

- **替代强化学习 (RL)**: FF 的本地“好度”函数可以被视为一种内在奖励信号，这使得 `SPL` 的路由决策学习可以被看作是一种策略梯度（Policy Gradient）方法的替代方案，但它避免了 RL 的高方差和不稳定性。
- **内在的持续学习 (CL)**: `SPL` 的抗灾难性遗忘特性，源于其内在的、基于内容寻址的专家激活机制。这提供了一种比 EWC/GEM 等需要二阶导数或存储旧数据的复杂 CL 算法更优雅、更具生物学可解释性的解决方案。
