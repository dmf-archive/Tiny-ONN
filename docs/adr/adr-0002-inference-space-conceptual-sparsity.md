---
title: "ADR-0002: Inference-Space Conceptual Sparsity and the Necessity of Dense Computation"
status: "Accepted"
date: "2025-10-06"
authors: "Ω Researcher, Tiny-ONN 课题组"
tags:
  [
    "architecture",
    "decision",
    "theory",
    "inference-space",
    "conceptual-sparsity",
    "variational-inference",
  ]
supersedes: "ADR-0001"
superseded_by: ""
---

# ADR-0002: 推断空间概念稀疏性与稠密计算的必要性

## 状态 (Status)

Proposed | **Accepted** | Rejected | Superseded | Deprecated

## 背景 (Context)

继 [ADR-0001](adr-0001-remove-moie-ffn.md) 统一架构后，本项目必须从第一性原理出发，重新定义“稀疏性”。`Tiny-ONN` 的核心目标是作为高效的变分推断引擎，最小化其变分自由能 (Variational Free Energy, VFE)。这一理论目标直接决定了其计算范式。

### 生物可解释性：稠密基质上的稀疏心智

人脑是理解这一概念的最佳类比。

- **计算/物理基质**: 人脑的物理网络由约 860 亿个神经元构成，浸泡在持续供应能量的电解质溶液中。该基质在物理层面是 **绝对稠密** 的，任何神经元原则上都可被即时调用，维持这一基质需要高昂的新陈代谢成本。
- **激活/推断过程**: 任何具体的认知过程（如一个想法）仅涉及极少数神经元的同步放电。这种激活模式在认知层面是 **高度稀疏** 的，构成了大脑能效的核心。

`Tiny-ONN` 的架构遵循同样的逻辑：为实现上层概念/认知的稀疏性与灵活性，底层的物理/计算基质必须是稠密且 **全局可用** 的。

### 概念稀疏 vs. 计算稀疏

基于此，我们将稀疏性区分为两个正交的概念：

- `概念稀疏性 (Conceptual Sparsity)`: 模型在处理输入时，在其 **推断空间 (Inference Space)** 中仅激活少数最相关的“概念通路”。这是一种*认知聚焦*，是模型智能、可解释性和抗灾难性遗忘的来源。
- `计算稀疏性 (Computational Sparsity)`: 物理硬件上实际执行的浮点运算量较少。这是传统稀疏网络的目标，但与 `Tiny-ONN` 的理论目标冲突。

核心问题是：为了实现 *概念上* 的稀疏，我们是否必须在 *计算上* 也追求稀疏？理论分析指出，为了获得稳定、精确的 VFE **解析解** ，物理计算过程必须是稠密的。

## 决策 (Decision)

我们决定，`Tiny-ONN` 的核心架构将 **拥抱计算的稠密性，以换取并优化推断空间中的概念稀疏性** 。我们不再将“计算稀疏”或降低 FLOPs 作为当前阶段架构设计的主要驱动力。

具体决策如下：

1. **维持计算图的稠密性**: 模型的计算流程将继续采用硬件亲和性高、并行效率高的稠密矩阵运算。
2. **聚焦概念稀疏的优化**: 研究重点将转向优化概念通路的**选择机制**，例如设计更精细的路由算法（如 `SARS`）和更具理论意义的成本函数。
3. **发展推断空间理论**: 投入资源发展一套数学工具，用于分析、可视化和度量推断空间的几何结构与动力学特性。

## 后果 (Consequences)

### 积极 (Positive)

- **POS-001**: **理论自洽**: 使架构设计与核心的 `IPWT/FEP` 理论及生物现实完全统一，消除了“为稀疏而稀疏”的内在矛盾。
- **POS-002**: **性能释放**: 能够充分利用现代 GPU 为稠密运算设计的全部算力，解除稀疏计算可能带来的硬件效率瓶颈。
- **POS-003**: **方向明确**: 研究方向被清晰地聚焦于提升模型进行概念推理和动态自组织的“质量”，而非单纯追求计算量的“节约”。

### 消极 (Negative)

- **NEG-001**: **理论复杂性**: “推断空间”等概念比 FLOPs 更为抽象，需要更复杂的数学工具进行分析，增加了理论的理解和沟通成本。
- **NEG-002**: **可扩展性悖论**: 本决策推迟了对一个根本性悖论的解决。即：为了获得驱动概念稀疏的精确梯度（神谕信号），我们在计算上引入了与概念空间维度成正比的稠密计算。当模型规模扩大时，该策略将遭遇算力墙。
- **NEG-003**: **实验验证挑战**: 在实验上量化和验证“概念稀疏性”的改善，比直接测量 FLOPs 的降低要更加复杂和间接。

## 考虑的备选方案 (Alternatives Considered)

### 方案 A: 采用计算稀疏范式 (如 Forward-Forward)

- **ALT-001**: **描述 (Description)**: 放弃反向传播，采用基于本地“好度”函数的 `Forward-Forward (FF)` 算法或其他变分采样方法。在这种范式下，计算和更新只发生在被激活的神经元上，从而实现真正的计算稀疏。
- **ALT-002**: **拒绝理由 (Rejection Reason)**:
  1. **理论等效性下的路径选择**: 理论分析证明，BP 和 FF 都在优化同一个 VFE 目标。但 BP 是该优化目标的**精确解析解**，而 FF 则是其**高效的、本地化的蒙特卡洛近似**。BP 通过全局反向传播获得确定性的“神谕信号”，而 FF 通过本地的、基于对比的“好度”函数（如原型匹配度）获得梯度的无偏估计。
  2. **解析解的压倒性优势**: 对于 ARC 这类需要高精度和快速迭代的小样本任务，解析解 (BP) 在训练速度、样本效率和收敛稳定性上拥有压倒性优势。FF 作为一种近似方法，其学习过程更慢且含有噪声。
  3. **拒绝不必要的妥协**: `Tiny-ONN` 是一个完全可微的系统。选择近似的 FF 而非精确的 BP，是自断经脉。这类似于脉冲神经网络（SNN）因其不可微性而被迫使用各种“代理梯度”。我们拥有最强大的优化工具，没有理由放弃它。

### 方案 B: 采用层次化近似路由

- **ALT-003**: **描述 (Description)**: 放弃对所有概念进行全局评估，转而采用分层 Top-K 或学习一个近似器来预测最优专家，从而在路由阶段降低计算量。
- **ALT-004**: **拒绝理由 (Rejection Reason)**: **时机不成熟**。这本质上是为解决“可扩展性悖论”而提出的方案。在当前阶段，我们的首要任务是深入理解小规模模型在 **精确解析解** 下的学习动力学。过早引入近似会模糊我们对核心问题的洞察。

## 参考文献 (References)

- **REF-001**: [ADR-0001: 移除 MoIE FFN 以实现架构统一性](adr-0001-remove-moie-ffn.md)
- **REF-002**: `DFC-Theory.md`
- **REF-003**: `1-background.md` (IPWT 理论)
