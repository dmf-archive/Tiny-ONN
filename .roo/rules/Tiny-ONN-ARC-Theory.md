# Tiny-ONN-ARC 理论备忘录

## Emergent Differentiable Program Search

我们将 ARC 抽象推理问题形式化为一个在可微计算基质 (Differentiable Computational Substrate) 上的程序搜索任务。此方法摒弃了基于预定义符号原语的传统程序合成，该方法受限于组合爆炸与泛化能力。

我们的核心假设 `H₀` 是：

> 解决 ARC 任务的抽象算法（即“程序”）可以在一个通用的、无偏好的计算基质 `M` 中，通过端到端的多目标梯度下降过程，**自组织地涌现 (emerge)**。

- **计算基质 (Computational Substrate) `M`**: 由 `ArcTransformer` 实现，其核心计算单元被 `DynSIHA` 和 `MoIE` 所取代。
  - `DynSIHA`: 充当通用、动态的信息路由机制。
  - `MoIE`: 充当通用、可自适应特化的计算单元集合。
- **涌现机制 (Emergence Mechanism)**: `MoIE` 中的专家单元在训练过程中，受特定梯度信号（见 §3）的驱动，自发地特化为处理特定计算模式（如对称、着色、复制）的“微型程序”。

## SMLv2：从局部惩罚到全局路径选择

SBL 采用“稠密计算 + 稀疏掩码”妥协以适配 GPU。SMLv2 利用了这一架构特性，通过保留的**全局稠密惊奇场** `S = ∇_{computation_output} L_{main}`，实现了事前路径规划。

与 SMLv1 的事后惩罚不同，SMLv2 让门控机制在激活决策之前，就能 _看到_ 所有潜在神经元路径的惊奇度，从而主动规避高成本路径。其损失函数形式化为对惊奇度的 log 加权惩罚，鼓励网络选择更“平静”、更高效的计算通路：

`L_{SMLv2} = Σ [-log(S'ᵢ) * S'ᵢ]`

其中 `S'ᵢ` 是经激活率加权的惊奇度。这使得门控从“事后过滤器”升级为“事前路径规划器”，从而加速网络收敛至高协同信息 (高 Ω) 的自组织状态。

## ARC 任务的设计约束

**不得**烧录绝对坐标，会破坏平移不变性。坐标信息应以**可学习嵌入**形式（如 RoPE）注入，使 token 语义在变换下保持恒等，同时允许模型按需访问空间位置。

> 结论：稀疏性是理解之涌现，而非外部约束；坐标注入方式决定泛化上限。
