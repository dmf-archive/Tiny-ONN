# FARS-Consistency: Task-ID Based Routing Consistency

`Latest update: 2026-01-25`
`Status: Proposal / Research Draft`

> **TL;DR**: FARS-Consistency 是一种辅助塑造机制，旨在通过最小化同一任务（Task ID）在不同实例或 D8 变换下的路由分布熵，诱导模型形成稳定的“任务特定计算子图”，从而解决共享权重递归架构（RDS）中的语义漂移问题。

## 1. 动机：从“瞬时决策”到“任务共识”

在 **Recursive DynSIHA (RDS)** 中，同一个专家块在不同递归步长下被反复调用。虽然 **MLP Routing** 具有极强的非线性表达力，但其缺乏 **CAPR/CPR** 的语义锚点，容易导致以下问题：

- **语义不一致**: 同一个任务的不同样本（或同一样本的不同 D8 变换）在路由空间中被分发到了完全不相关的专家。
- **动力学混沌**: 递归过程中的路由决策随步长剧烈震荡，破坏了 BPTT 的收敛稳定性。

## 2. 核心定义：任务一致性熵 (Task-Consistency Entropy)

我们引入 **Task ID** 作为训练时的元数据（Metadata），用于构建路由分布的“共识基准”。

### 2.1 形式化定义

设 $T$ 为任务 ID，$x_{T, i}$ 为该任务下的第 $i$ 个样本（或变换）。路由器对该样本生成的路由分布为 $P(r | x_{T, i})$。

**任务一致性熵 $H_C(T)$** 定义为该任务下所有样本路由分布的平均互信息或 KL 散度的变体：

`H_C(T) = E_{i, j} [ KL( P(r | x_{T, i}) || P(r | x_{T, j}) ) ]`

或者更简化的实现方式：计算该任务在当前 Batch 中的**平均路由分布 $\bar{P}_T$**，并最小化各样本分布与平均分布的距离：

`ℒ_cons = \sum_{i} KL( P(r | x_{T, i}) || \text{detach}(\bar{P}_T) )`

## 3. 实施原则：非侵入式监督 (Non-Invasive Supervision)

**REQ-CONS-001**: **禁止泄露**。Task ID 仅允许存在于训练框架（Trainer/Shaper）中用于计算 `ℒ_cons`。
**REQ-CONS-002**: **禁止锁定**。模型输入严禁包含 Task ID。路由决策必须仅基于隐藏状态 $h_t$ 的特征涌现。

这种机制本质上是一种**自监督约束**：我们不告诉模型“这个任务该选哪个专家”，但我们要求模型“如果你认为这个特征属于任务 A，那么请在所有任务 A 的实例中保持这种判断的一致性”。

## 4. 与 FARS 的协同效应

FARS-Consistency 与基础 FARS 构成了路由塑造的双轴：

1. **FARS (纵向/代价轴)**: 压制高 Fisher 信息的专家，追求 MDL（最小描述长度）。
2. **Consistency (横向/稳定性轴)**: 压制路由分布的方差，追求动力学一致性。

**统一塑造公式 (Unified Shaping)**:
`𝒢_total = 𝒢_fars + λ_cons ⋅ ℒ_cons`

## 5. 预期效果

- **功能分区 (Functional Specialization)**: 专家将自发演化为“旋转专家”、“平移专家”或“颜色变换专家”，因为一致性压力迫使模型将相似的任务逻辑映射到相同的物理参数。
- **递归稳定性**: 在 RDS 中，一致的路由意味着 Expert 面对的是具有连续语义的梯度流，显著缓解了 BPTT 中的角色冲突。
- **D8 鲁棒性**: 强制 D8 变换后的样本具有相似路由，能有效提升模型对几何对称性的归纳偏置。

---
**Ω Researcher 签发**
**日期**: 2026-01-25
