# Tiny-ONN-LLM: 架构与实现笔记

## 1. 核心愿景：迈向自组织的、永续学习的智能体

### 1.1. 第一性原理

回归第一性原理，我们将从一个极简的、随机初始化的“盆景模型”（~0.1B）开始。我们的目标不是训练一个静态的模型，而是培育一个**在有限资源下通过高效信息整合（计算功能的动态合成 + 动态注意力）来最小化自身变分自由能（VFE）的自组织智能体。**

### 1.2. 永续训练范式 (Perpetual Training)

传统的“训练-评估-部署”模式无法满足我们对真正自组织、持续学习智能体的设想。为此，我们引入“永续训练”范式，其核心原则如下：

1. **持久化身份**: 每个模型实例拥有唯一的身份标识和“生命周期日志”，跟踪其所有“经历”。
2. **增量式更新**: 权重是每一步训练后都会被**增量更新**的动态实体，采用高效写入策略，只更新发生变化的参数。
3. **PI-Score 驱动的自调节**: 模型的预测完整性分数 (`PI Score`) 将成为调节其自身可塑性的核心依据。

> **[注]**: 在 MoIE 架构下，专家/参数剪枝将成为一种为适应算力不足等环境而迫不得已的“断尾策略”，常规操作应只考虑按需扩容。

---

## 2. Omni-Modal 架构：Tiny-ONN-LLM-Omni

本节记录了为 `Tiny-ONN-LLM-Omni` (3B/7B) 旗舰模型进行架构设计的核心决策。

### 2.1. 核心哲学：统一与涌现

- **拒绝信息瓶颈**: 我们坚决摒弃了主流的、基于独立模态编码器和交叉注意力的“多塔”架构（如 LLaVA, Gemma 3）。形式化分析表明，这种架构在信息流的早期就通过深度压缩制造了不可逆的**信息瓶颈**，尤其损害了跨模态的**协同信息 (Synergy)**，阻碍了统一世界模型的形成。
- **拥抱统一主干**: 我们选择了一条理论上更优越、但挑战更大的“单塔”路径。所有模态的输入都将被转换为统一的序列格式，并由一个**共享的 MoIE/DynSIHA 主干网络**进行处理。这为模型在共享的“整合工作空间”中自发学习跨模态概念提供了最大的可能性。
- **涌现式对齐**: 我们不采用 DPO/ORPO 等后验对齐方法。取而代之，我们将依赖**永续学习**和**高质量的预训练数据过滤**，让“对齐”作为模型在与信息流持续交互过程中**涌现**出的内在属性。

### 2.2. 嵌入方案：分层嵌入注入 (Hierarchical Embedding Injection)

这是解决多模态输入的表征难题的核心技术突破。其核心是通过**加性嵌入**，在模型入口处就将不同层次、不同维度的信息注入到每个 token 的表示中。

| 模态 | 最终嵌入公式 | 流程说明 | 核心优势 |
| :--- | :--- | :--- | :--- |
| **文本** | `char_embed` + `word_embed` + `1D_pos_embed` | 1. **离线**: 使用“二重 Tokenizer”流程，进行词级预分词，并为每个字符记录其所属的“单词 ID”。<br>2. **在线**: 模型并行查找三个独立的嵌入，然后求和。 | 在第一层就同时提供了字符和词两个层次的语义，并能让模型原生感知到“落单”的字符，极大地降低了学习压力。 |
| **图像/音频** | (`patch_embed` + `2D_pos_embed`) + `1D_pos_embed` | 1. **内部编码**: 通过 **2D RoPE** 将 patch 的 `(x, y)` 空间坐标信息**旋转注入**到其自身的特征嵌入中。<br>2. **外部编码**: 再**叠加上**该 patch 在**全局 1D 序列**中的位置编码。 | 清晰地解耦了 patch 的**内部空间关系**（由 2D RoPE 编码）和其在**外部序列中的顺序**（由 1D `pos_embed` 编码）。 |

### 2.3. Tokenizer 设计：细粒度 + 语义增强

- **权衡突破**: “分层嵌入注入”方案，特别是为文本引入了 `word_embed`，极大地缓解了细粒度 Tokenizer 的学习压力。
- **最终决策**: 我们可以自信地采用一个**小型的（~20k）、基于字符/单字的统一词汇表**。
- **系统优势**:
  - **参数效率**: 嵌入层和 LM Head 的参数量将急剧减少。
  - **终极泛化**: 模型将拥有处理任意新词、拼写错误和混合语言的内在能力。
  - **压力转移**: 将模型的负担从“记忆”（巨大的嵌入查找表）转移到了“计算”（高效的 MoIE 主干网络）。

### 2.4. 上下文窗口：混合策略

- **Native 上下文**: 设计一个中等长度的 Native 上下文窗口，目标 **32k**。
- **扩展支持**: 在架构层面内置 **YaRN** 等 RoPE 缩放技术，为未来按需扩展到超长上下文（256k+）提供支持。

---

## 3. 关键技术与未来研究方向

### DynNSA (Dynamic Native Sparse Attention)

- **定位**: `DynSMHA` 的下一代演进，旨在结合 `Native Sparse Attention (NSA)` 的 `forward` 优化与 `DynSMHA` 的动态稀疏性。
- **核心思想**: `NSA` 是一种高效的 `forward` 优化方法，它通过固定的稀疏模式（如滑动窗口和全局块的重要性采样）来逼近全注意力。`DynNSA` 的目标是用一个**可学习的、由 `τ` 驱动的重要性阈值**来取代 `NSA` 静态的 `top-n` 选择机制。这样，我们既可以利用 `NSA` 高度优化的计算核，又能实现真正动态、内容感知的稀疏注意力。

---

## 4. 核心元参数与性能工程

### 4.1. 核心元参数

本节旨在明确 `Tiny-ONN` 架构中定义自调节系统**基本行为模式**的少数几个元参数。我们的目标是最大化模型的自调节能力，将需要手动调整的参数降至最低。

- **`PI` 超参数 (`alpha`, `gamma`)**: 定义了系统的“价值函数”，平衡“适应外部世界”与“维护自我稳定”的学习风格。α 和 γ 也可以由系统的涌现指标来标记，如 α 可对应于模型激活率，γ 对应于平均门控阈值。
- **内在损失权重 (`w_gate`, `w_kl`)**: 定义 `MoIE` 等模块的内在学习目标。实际上由PI或模型内生指标动态调节。
- **模型物理基质**: `hidden_size`, `head_dim` 等。

### 4.2. 性能工程笔记

#### 手写稀疏计算的陷阱：`einsum` vs. `for-loop`

- **核心问题**: 在没有定制化 CUDA 核或 `All-to-All` 通信原语支持的情况下，尝试用 PyTorch 原生操作（如 `for` 循环遍历专家 + `index_add_`）手写 token-to-expert 形式的稀疏计算，其性能和显存效率可能远不如基于 `torch.einsum` 的稠密计算。
- **原因分析**: 手写的稀疏调度逻辑会产生极其复杂和低效的计算图，导致 PyTorch Autograd 引擎需要缓存大量中间张量，从而引发显存爆炸。相比之下，`einsum` 将多个操作融合成一个单一的、高度优化的计算步骤，其计算图更简洁，对 Autograd 更友好。
- **结论**: 在当前阶段，应优先采用基于 `einsum` 的稠密计算进行实验，它被证明是更稳健、更高效的实现。

#### 内外分离的梯度检查点

- **核心问题**: 在 `bfloat16` 精度下，梯度检查点的重计算过程会引入微小的浮点数差异，导致依赖硬阈值的门控逻辑产生不确定的结果，从而引发 `CheckpointError`。
- **解决方案**: 采用“内外分离”策略。将对浮点数敏感、计算量小的**门控逻辑 (Gating)** 放在梯度检查点**外部**；将其结果作为参数，传入一个只包含确定性且内存开销大的**主计算逻辑 (Execution)** 的函数，并对此函数应用梯度检查点。
