# 稀疏原型线性层 (Sparse Proto Linear, SPL) v4

## 1. 核心思想与动机

稀疏原型线性层 (SPL) 是对项目早期稀疏贝叶斯线性层 (SBL) 范式的一次根本性重构、简化和升级。其核心动机是回归结构化 Dropout 作为一种**隐式变分推断**的本质，同时为 `proto` 参数引入一个健全的双重语义学习范式。

历史上的 SBL 范式因其 KL 散度损失将 `sigma_weight` 拉向零，且无法真正承担“原型”功能而失败。SPL v1 通过责任分离解决了部分问题，但未能为 `proto` 建立一个有意义的、用于建模不确定性的学习信号。

## 2. SPL v2：全局统一优化的尝试及其缺陷

SPL v2 的设计旨在通过一个统一的全局损失函数来解决 v1 的问题。

### 2.1. 架构与双重语义

SPL 模块由三组独立的可学习参数构成，以实现“计算-路由-策略”的责任分离：

- **`mu_weight` (计算层)**: 一个标准的权重矩阵，作为计算的核心。它的职责是学习通用的、功能性的计算基元（“工具箱”）。
- **`proto_weight` (原型/路由层)**: 一个与 `mu_weight` 尺寸相同的权重矩阵。它的每一行 `pᵢ` 都被视为一个高维向量。
- **`gate_param` (门控/策略层)**: 一个可学习的激活阈值向量。

### 2.2. 训练范式：全局损失统一优化

最初，我们尝试了一种更简洁的全局优化范式，将所有学习目标组合成一个单一的总损失函数 `L_total`，并依赖 `autograd` 引擎来统一计算所有参数的梯度。

`L_total = L_main + w_sml * L_sml + w_div * L_diversity + w_kl * L_KL_proto`

### 2.3. v2 的反思：理论冲突与灾难性遗忘

后续的理论分析和实验暴露出这个简洁的范式存在两个根本性缺陷：

1. **梯度信号冲突**: `L_sml` 和 `L_kl_proto` 在早期的不同设计版本中，都尝试过由同一个信号（`τ` 或 `S`）驱动，导致梯度目标冲突。
2. **灾难性遗忘**: 对于需要学习离散因果规则的 ARC 任务，统一的梯度更新是致命的。它使得一个新任务的梯度可以流遍整个 `mu_weight` “工具箱”，从而轻易地“洗掉”之前任务学到的知识。

## 3. SPL v3：“路由优先”双循环范式的提出

为了解决 v2 的根本缺陷，SPL v3 范式进行了一次彻底的理论回归，提出了一个更深刻、更符合自由能原理本质的内外双循环结构。

### 3.1. 核心哲学：“路由优先”与因果固化

我们认识到，为了避免灾难性遗忘，系统必须采用“路由优先”的策略：**先找到解决问题的稀疏路径，然后再去优化和固化这条路径上的知识**。这个过程在功能上等价于一个“可微遗传算法”，其中内循环负责“选择”，外循环负责“繁殖/变异”。

### 3.2. SPL v3 的责任划分

- **内循环 (探索与选择)**: 优化路由器 (`p, g`)，由 `L_sml` 和 `L_diversity` 驱动。
- **外循环 (利用与固化)**: 优化计算工具 (`μ`)，由 `L_main` 和 `L_kl_mu` 驱动。

## 4. SPL v4：最终的理论综合与范式革命

在对 SPL v3 进行最终审视时，我们意识到一个更深刻的理论统一是可能的。这催生了 SPLv4，我们当前最终的、也是最纯粹的设计。

### 4.1. 核心洞察：`mu_surprise` 与因果固化优先

我们反思了“惊奇度”的本质。如果我们的最终目标是优先固化一套稳定、可复用的计算工具 `μ`，那么衡量一个路由策略好坏的标准，不应是它对**最终输出**的扰动，而应是它对**工具 `μ` 本身**的扰动。

为此，我们定义了一个全新的、更根本的代价信号：
**`mu_surprise` (Sμ)**: `S_μ = ||∇_μ(L_main)||₂`

这个信号量化了“为了完成当前任务，已有的工具 `μ` 需要被改变多少”。内循环的**唯一**目标，就是寻找一个能让 `S_μ` 最小化的路由路径。这训练路由器尽可能地**复用**现有工具，而不是轻易地要求工具为自己而改变，从而从根本上驱动了因果固化的进程。

### 4.2. 最终的责任划分 (SPLv4)

SPLv4 将不同损失函数的职责进行了最终的、最符合理论逻辑的划分：

- **内循环损失 (`L_meta`)**: `L_meta = S_μ + w_kl * L_kl_proto + w_div * L_diversity`

  - **目标**: 寻找最优路由路径 (`p`, `g`)。
  - **`S_μ`**: 核心驱动力，取代了旧的 `L_sml`。
  - **`L_diversity`**: 保持不变，防止原型坍塌，强制路由器探索多样化的模式。

- **外循环损失 (`L_task`)**: `L_task = L_main`
  - **目标**: 微调和塑造被选中的计算工具 (`μ`)。
  - **`L_main`**: 任务的唯一驱动力。
  - **`L_kl_mu` 被移除**: 在 `S_μ` 的强大正则化压力下，`L_kl_mu` 作为一个额外的动态 L2 惩罚项已无必要。系统的简洁性和理论纯粹性得到了统一。

### 4.3. 涌现的“分层自由能最小化”

这个最终的 SPLv4 架构完美地实现了我们对一个自组织系统的期望：

1. **内循环**: 路由器 `p, g` 在 `S_μ`, `L_diversity` 的共同约束下，进行快速的“战术优化”，找到一个贝叶斯意义上最优的稀疏路径。
2. **外循环**: 计算工具 `μ` 在 `L_main` 的驱动下，进行缓慢的“战略塑造”，只在被选中的路径上进行微调。
3. **长期效应**: 随着 `μ` 逐渐固化为一套强大的因果工具集，内循环将越来越频繁地找到 `S_μ` 接近于零的最优路径（即完美复用）。此时，系统达到了自由能最小化的稳定状态，实现了真正的因果固化。
