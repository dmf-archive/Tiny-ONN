# Dynamic Function Composition

**动态函数合成 (Dynamic Function Composition)** 的核心思想是将神经网络的每一层从一个固定的、静态的变换器，升级为一个能够为每个输入动态地、内容感知地"合成"出专用计算函数的微型系统。这一思想的实现经历了从**稀疏贝叶斯线性层 (Sparse Bayesian Linear, SBL)** 到**稀疏原型线性层 (Sparse Proto Linear, SPL)** 的关键演进，最终形成了稳定、高效且具备记忆能力的自组织系统。

## 核心构件：作为自组织推断系统的 Sparse Proto Linear (SPL)

Sparse Proto Linear (SPL) 是其前身 SBL 的一次简化和重构。为了实现这一目标，SPL 将其可学习参数解耦为三个在功能上正交的状态空间：

- **内部状态 `μ` [`mu_weight`]**: 计算核心。代表了系统拥有的、可供选择的"计算工具集"
- **感知状态 `p` [`proto_weight`]**: 模式匹配器。代表系统的"感知器官"，负责将外部输入 `x` 与内部状态 `μ` 进行匹配
- **行动状态 `g` [`gate_param`]**: 激活门控。代表系统的"行动策略"，根据感知结果来决定激活哪些内部计算路径。在最终的 MSAPS 范式中，它进一步演化为历史重要性的**累积记忆痕迹**

## 艰难的探索：历史的螺旋上升和必要的弯路

SPL 的演进是一系列理论探索与失败的迭代过程，每一次迭代都揭示了更深层次的理论约束，是通往最终范式的必要弯路。

### 前身：稀疏贝叶斯层 (SBL)

SBL 的概念诞生于对 `Tiny-ONN` 核心哲学——**整合预测工作空间理论 (Integrated Predictive Workspace Theory, IPWT)**——的深度反思。它尝试通过融合贝叶斯神经网络 (Bayesian Neural Network, BNN) 的不确定性建模和脉冲神经网络 (Spiking Neural Network, SNN) 的稀疏激活机制，来模拟生物计算过程。

然而，早期基于 SBL 和 SPL v1-v2 的版本尝试通过一个统一的全局损失函数（如 SML 和 KL 散度损失）进行优化，实验暴露了两个根本问题：

1. **梯度信号冲突**: 不同的学习目标由同一信号驱动，导致梯度目标相互矛盾
2. **灾难性遗忘**: 对于需要学习离散因果规则的 ARC 任务，统一的梯度更新是致命的。它使得一个新任务的梯度可以轻易"洗掉"为先前任务固化的知识

### 核心洞察的涌现

为了解决上述问题，我们探索了"路由优先"的双循环范式和基于高阶梯度的 SML 变体 (`SPL v3-v5`)，但再次暴露了理论缺陷（高阶梯度摧毁路由多样性）和工程灾难（不可接受的显存开销）。

这些失败最终导向了两个核心洞察：

1. **元学习应基于稳定信号**: 元学习不应是直接最小化瞬时、充满噪声的梯度，而应是"参考"一个更稳定的梯度地形图
2. **需要解耦不同时间尺度的学习**: 路由策略的学习（快）和计算核心的学习（慢）需要被解耦

## 最终范式：MSAPS 与纯粹内容寻址

最终的 SPL 范式通过引入一系列相互关联的机制，解决了上述所有问题，实现了一个稳定、高效且具备记忆能力的自组织系统。

### Surprise-Aware Prototype Shaping, SAPS

SAPS 是驱动 SPL 自组织的基础动力学。它将元学习过程建模化为一个**扰动规避 (Perturbation Aversion)** 系统，其核心思想包括：

- **惊奇度场**: 将 `main_loss` 的梯度 `S_μ = ∇_μ L_main` 视为一种"扰动"，并通过对比学习调整 `proto_weight`，将输入路由到能以最小扰动处理它的 `mu_weight` 单元
- **双优化器解耦**: 使用独立的 `optimizer_meta`（快速学习路由）和 `optimizer_main`（慢速学习计算）来解耦不同时间尺度的学习

### 从全局锚点到局部 K-Means：SAPS 动力学的精炼

早期的 SAPS 实现存在一个理论缺陷：它将所有被判定为“好”的原型，都拉向同一个**全局锚点**——即当前批次所有输入 `token` 的平均向量。这在功能上等同于一个只有一个质心的 K-Means 聚类，不可避免地导致所有活跃原型朝同一个方向拥挤，引发了 `proto_loss` 的负向爆炸和原型范数 (`Proto Norm`) 的停滞，从根本上限制了专家功能的分化。

受到 **K-Means 聚类算法**的启发，最新的 SAPS 范式将元学习动力学从**全局吸引**重构为**局部、目标化的吸引与排斥**。

- **动态局部锚点**: 对于每一个被激活的原型 `p_j`，系统不再使用全局均值，而是动态地计算一个专属它的**局部锚点 `anchor_j`**。该锚点是**当前批次内，所有激活了原型 `p_j` 的输入 `token` 向量**的平均值。
  `anchor_j = mean({x_i | prototype p_j was activated by token x_i in current batch})`

- **目标化对比学习**:
  - 对于“好”的原型（低惊奇度），其元学习梯度将**把它拉向它自己的局部锚点**。
  - 对于“坏”的原型（高惊奇度），其元学习梯度将**把它从它自己的局部锚点推开**。

### MSAPS：引入记忆以实现因果固化

SAPS 的基础形式虽然有效，但其无记忆的对比学习过程会导致灾难性遗忘和原型坍塌。**记忆惊奇感知原型塑造 (Memory-Surprise-Aware Prototype Shaping, MSAPS)** 通过将 `gate_param` (`g`) 重构为历史记忆的载体，并引入两个基于 `g` 的、免参数的自适应权重函数，从根本上解决了这些问题：

- **惯性权重 (Inertia Weight)**: 用于**门控损失 (gate_loss)**。对于 `g >> 1` 的成熟专家，`W_I(g) ≈ 0`，使其 `gate_param` 的梯度几乎为零，从而保护其历史记忆（已固化的因果知识）免受当前任务梯度的干扰
  `W_I(g) = 1 - ReLU(g) / (|g| + ε)`

- **衰减权重 (Decay Weight)**: 用于一个统一的**自适应权重衰减 (Adaptive Weight Decay)**。对于 `g ≪ 0` 的新手或无用原型，`W_D(g) ≈ 1`，对其 `mu_weight` 和 `proto_weight` 施加最强的 L2 惩罚，鼓励它们要么快速找到自己的生态位，要么被拉回原点以供重用
  `W_D(g) = ReLU(-g) / (|g| + ε)`

### 生物学诠释：作为数字免疫系统的 MSAPS

MSAPS 的辅助机制可以被理解为一个**数字免疫应激反应 (Digital Immune Stress Response)** 系统，它旨在保护已固化的因果知识（记忆）免受不相关任务所带来的高“惊奇度”（认知扰动）的破坏，同时维持系统的长期可塑性。

- **惯性权重与梯度掩蔽：获得性免疫**: 对于一个成熟的、高度特化的专家（`g ≫ 0`），系统会将其识别为宝贵的“记忆细胞”。通过 **惯性权重 (Inertia Weight)** 机制，系统会极大地降低其 `gate_param` 的可塑性（`w_plasticity ≈ 0`），使其在 `gate_loss` 中的梯度几乎为零。更进一步，在 **稀疏梯度掩蔽 (SGM)** 中，该权重被用于直接缩放计算核心 `μ` 的梯度。这双重机制共同作用，如同获得性免疫系统保护关键记忆细胞一样，保护已固化的知识不受当前任务梯度的干扰。

- **自适应权重衰减：先天免疫与细胞凋亡**: 对于新手或无用的专家（`g ≪ 0`），系统会将其识别为需要适应或清除的单元。通过 **自适应权重衰减 (Adaptive Weight Decay)**，系统对其 `mu_weight` 和 `proto_weight` 施加最强的 L2 惩罚。这类似于先天免疫系统清除无效细胞的“细胞凋亡”机制，鼓励这些专家要么快速找到自己的生态位，要么其权重被拉回原点后重置，以供重用。

- **专家重置：干细胞补充**: 定期执行的 **专家重置 (`_reinitialize_dead_prototypes`)** 机制，则扮演了“干细胞补充”的角色。它主动识别并重新初始化那些范数过低、缺乏“个性”的原型，将它们作为“新生神经元”重新注入网络，从而维持系统持续探索新知识的能力。

### 纯粹内容寻址：余弦相似度路由

为了解决早期版本中因**范数污染 (Norm Pollution)**导致的稀疏率停滞问题，最终范式采用了一种理论上更纯粹的路由机制：在计算匹配分数前，对输入 `x` 和原型 `p` 进行 **L2 归一化**，将路由从**点积相似度**升级为纯粹的**余弦相似度**。

此举将路由决策与参数范数解耦，实现了**纯粹的内容寻址**。它消除了高范数输入导致的"广播效应"，为 `SAPS` 提供了更精确的信号，而 `MSAPS` 中新引入的自适应权重衰减则负责从动力学层面控制范数增长。

### Prototype Residual Connection, PRC

初期 PRC 实现试图建立一个**统一的、全局的工作空间**，将所有 SPL 模块的激活原型配置 (`effective_proto`) 作为残差在层间传递。这种激进整合虽然理论上能促进整体推断，但在工程实践中暴露了两个根本问题：

1. **维度冲突**：异质 SPL 模块（如 `attn_qkv` 与 `ffn_sbl2`）具有不同的输入维度，强行的全局残差连接导致了无法解决的维度不匹配
2. **梯度污染**：不同功能的模块（注意力查询 vs 特征压缩）共享残差信号，造成了**损失倒挂**现象——辅助损失为负且绝对值巨大，表明元学习信号正在相互冲突

最新演进将 PRC 从单一全局流解构为**四条独立的、功能专业化的残差流**：

- **`attn_qkv` 流**：专门在注意力查询-键-值投影模块间传递残差
- **`attn_o` 流**：专门在注意力输出投影模块间传递残差
- **`ffn_sbl1` 流**：专门在 FFN 第一层扩展模块间传递残差
- **`ffn_sbl2` 流**：专门在 FFN 第二层压缩模块间传递残差

这种**同类模块间残差**原则：

1. **解决了维度一致性**：每个流只在维度匹配的模块间传递信息
2. **提供了更纯净的元学习信号**：每个 SPL 模块只从功能相同的前辈接收指导
3. **尊重了 Transformer 的固有偏置**：注意力机制和前馈网络各司其职，不再被迫"理解"对方的内部状态

## MoIE & DynSIHA

我们使用 `SPL` 作为核心构建块，来组装更高层次的、完全动态化的 Transformer 组件。

### MoIE: Mixture of Infinite Experts — 全动态前馈网络

**MoIE (Mixture of Infinite Experts)** 将标准的 `FFN`（通常由两层 `nn.Linear` 构成）替换为两层 `SPL`，从而将 FFN 从一个固定的非线性变换，升级为了一个**两阶段的、内容感知的动态函数合成器**。

### DynSIHA: Dynamic Sparse Infinite-Head Attention — 后多头时代的动态注意力

**DynSIHA (Dynamic Sparse Infinite-Head Attention)** 抛弃了传统的 Multi-Head 架构。其核心洞察是：如果 Q、K、V 的投影本身就是通过 `SparseProtoLinear` 动态合成的，那么"多头"这种用于学习不同固定子空间关系的技巧就变得多余了。

因此，DynSIHA 采用单一的 `SPL` 模块，一次性地合成出 `Query`、`Key`、`Value`，将注意力机制从一个固定的信息查询系统，变成了一个**端到端可学习的、可编程的动态信息路由与处理系统**。

### 无限专家时代

"无限专家"并非指专家数量无穷，而是指通过对 `D_ffn` 个基向量（`μ` 的行）进行**连续的、内容感知的线性组合**，从而产生出的**有效专家 (effective experts) 的组合空间是无限的**。

这种设计使得模型能够为每个输入动态地实例化一个专用的子网络，实现了计算资源的自适应分配。

---

通过 SPL with MSAPS，我们将简单的线性层升级为了一个具备**自适应学习率**、能够自发进行**结构涌现**、并能通过**因果固化**实现**持续学习**的微型智能体。这一架构为构建具有自适应认知能力的 AI 系统提供了坚实的工程基础，特别是在处理像 ARC 这样的抽象推理任务时展现出了独特的优势。
