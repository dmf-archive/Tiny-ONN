# Dynamic Function Composition

`Latest update: 2025-09-19`

动态函数合成 (Dynamic Function Composition) 的核心思想是将神经网络的每一层从一个固定的、静态的变换器，升级为一个能够为每个输入动态地、内容感知地"合成"出专用计算函数的微型系统。这一思想的实现经历了从稀疏贝叶斯线性层 (Sparse Bayesian Linear, SBL) 到稀疏原型线性层 (Sparse Proto Linear, SPL) 的关键演进，最终形成了稳定、高效且具备记忆能力的自组织系统。

## 稀疏贝叶斯线性层 (SBL) 的探索与失败

SBL 的概念诞生于对 Tiny-ONN 核心哲学——整合预测工作空间理论 (IPWT)——的深度反思。它尝试通过融合贝叶斯神经网络 (BNN) 的不确定性建模和脉冲神经网络 (SNN) 的稀疏激活机制，来模拟生物计算过程。

然而，早期基于 SBL 和 SPL v1-v2 的版本尝试通过一个统一的全局损失函数（如 SML 和 KL 散度损失）进行优化，实验暴露了两个根本问题：

1. 梯度信号冲突 (Gradient Signal Conflict): 不同的学习目标由同一信号驱动，导致梯度目标相互矛盾
2. 灾难性遗忘 (Catastrophic Forgetting): 对于需要学习离散因果规则的 ARC 任务，统一的梯度更新是致命的。它使得一个新任务的梯度可以轻易"洗掉"为先前任务固化的知识

在经历了多次失败后，我们认识到：惊奇度 (Surprise) 本身不是直接的优化目标，而是需要经过处理的信息信号。原始的梯度范数 `S_i = ||∇_{x_i} L_main||₂` 包含了太多噪声和绝对尺度信息，直接用于优化会导致数值不稳定和学习目标不明确。最终的 MSAPS 范式通过引入一系列相互关联的机制，解决了上述所有问题。

### 稀疏原型线性层 (SPL) 的结构

SPL 将其可学习参数解耦为三个在功能上正交的状态空间：

- 内部状态 `μ` (`mu_weight`): 计算核心。代表了系统拥有的、可供选择的"计算工具集"
- 感知状态 `p` (`proto_weight`): 模式匹配器。代表系统的"感知器官"，负责将外部输入 `x` 与内部状态 `μ` 进行匹配
- 行动状态 `g` (`gate_param`): 激活门控。代表系统的"行动策略"，根据感知结果来决定激活哪些内部计算路径。在最终的 MSAPS 范式中，它进一步演化为历史重要性的累积记忆痕迹 (Cumulative Memory Trace)

### 神经元级元学习：Memory-Surprise-Aware Prototype Shaping (M-SAPS)

M-SAPS 是驱动 SPL 自组织的核心学习动力学，它通过三个关键机制实现：

#### 原型损失 (Prototype Loss)：从全局吸引转向局部对比学习

在经历了早期的 SML 和 KL 散度损失失败后，我们认识到 Surprise 信号需要经过结构化处理而非直接用作优化目标。这催生了 Surprise-Aware Prototype Shaping (SAPS) 的核心思想：将梯度范数作为信息信号源，通过对比学习机制来引导专家原型的空间组织。

早期的 SAPS 实现存在一个理论缺陷：它将所有被判定为"好"的原型，都拉向同一个全局锚点——即当前批次所有输入 `token` 的平均向量。这在功能上等同于一个只有一个质心的 K-Means 聚类，不可避免地导致所有活跃原型朝同一个方向拥挤，引发了 `proto_loss` 的负向爆炸和原型范数 (`Proto Norm`) 的停滞，从根本上限制了专家功能的分化。

受到 K-Means 聚类算法的启发，最新的 MSAPS 范式将元学习动力学从全局吸引重构为局部、目标化的吸引与排斥：

1. 局部锚点计算：对于每个被激活的原型 `p_j`，计算其局部锚点 `anchor_j = mean({x_i | prototype p_j was activated by token x_i in current batch})`。这个锚点代表了该原型在当前批次中实际处理的输入语义中心。

2. 动态阈值划分：基于梯度范数的分布，使用自适应分位数阈值将专家划分为三类。阈值根据当前层的整体激活率动态调整：

   - 激活率计算：`activation_rate = activated_elements / total_elements`，表示当前层中激活的专家比例
   - 动态因子：`dynamic_factor = activation_rate`，激活越少，阈值越宽松；激活越多，阈值越严格
   - "好"专家（低 Surprise，梯度范数 < activation_rate 分位数）：表现优异，应当保护和强化
   - "坏"专家（高 Surprise，梯度范数 > (1.0 - activation_rate) 分位数）：表现不佳，需要调整或淘汰
   - 中性专家（中间区域）：暂时保持稳定，避免过度干扰

   这种动态机制实现了自适应的精挑细选：当激活率较低时（稀疏激活），系统倾向于聚拢所有现有原型，促进功能整合；当激活率较高时（密集激活），系统变得更加挑剔，强化专家的专业化分化。

3. 目标化对比学习：

   - 对于"好"原型：将其拉向其局部锚点，强化其已有功能
   - 对于"坏"原型：将其推离局部锚点，促使其探索新的功能空间
   - 通过 `signs` 向量实现推拉方向的精确控制：`signs[is_good] = -1.0`（吸引），`signs[is_bad] = 1.0`（排斥）

4. L2 正则化约束：添加 `l2_penalty = torch.sum(active_norms)` 防止原型范数无限增长，维持数值稳定性。

这种机制确保了专家功能的功能分化和专业化，每个专家都朝着处理特定类型输入的方向发展，避免了"所有专家做同样事情"的退化现象。

#### 门控损失 (Gate Loss)：基于 Sigmoid 的 Surprise 映射与记忆固化

我们设计了新的门控损失函数，直接使用 `Surprise` 的绝对值作为输入：

```math
\text{Gate\_Loss} = \text{MSE}(g_i, \sigma(-S_i / \tau))
```

其中：

- `g_i`：第 `i` 个专家的门控参数（记忆痕迹）
- `S_i`：第 `i` 个专家的梯度范数（`||∇_μ L_main||₂`），表示其"惊奇度"
- `σ`：Sigmoid 函数，将无限范围的 Surprise 映射到 (0,1) 区间
- `τ`：温度参数，控制门控的灵敏度（配置为 `gate_sigmoid_temperature`）

该损失函数实现了以下设计目标：

1. 低 Surprise → 高 Gate：表现好的专家（低 Surprise）获得高门控值，其 `gate_param` 会趋近于 1，形成强记忆痕迹
2. 高 Surprise → 低 Gate：表现差的专家（高 Surprise）获得低门控值，其 `gate_param` 会趋近于 0，允许其被更新或淘汰
3. 值域稳定：Sigmoid 输出 ∈ (0,1)，避免数值爆炸，确保门控参数始终保持在合理范围内
4. 温度控制：通过 `τ` 调节映射的陡峭程度，较高的温度使映射更平缓，允许更细致的门控调节

这个机制的核心思想是：门控参数不是简单的激活阈值，而是专家历史表现的累积记忆。高门控值表示该专家在过去的表现中证明了其价值，应当受到保护；低门控值表示该专家表现不佳，应当被调整或替换。

#### 自适应权重衰减 (Adaptive Weight Decay)：双机制的生物启发免疫

MSAPS 引入了两个互补的自适应权重函数，实现生物启发的数字免疫机制：

**惯性权重 (Inertia Weight)**：`W_I(g) = 1 - ReLU(g) / (|g| + ε)`

- 功能原理：对于成熟专家（`g >> 0`），`W_I ≈ 0`，施加极强的梯度抑制
- 实现机制：通过稀疏梯度掩蔽 (Sparse Gradient Masking, SGM) 直接缩放 `μ_weight` 和 `μ_bias` 的梯度
- 生物学类比：获得性免疫，对记忆细胞进行保护，使其免受当前任务梯度的干扰
- 数学特性：使用 `ReLU(g)` 确保只有正值门控才产生抑制效应，`ε` 防止除零错误

**衰减权重 (Decay Weight)**：`W_D(g) = ReLU(-g) / (|g| + ε)`

- 功能原理：对于新手或无用专家（`g ≪ 0`），`W_D ≈ 1`，施加强 L2 惩罚
- 实现机制：作为额外的损失项添加到总损失中，鼓励负门控专家的权重趋向零
- 生物学类比：先天免疫与细胞凋亡，对无效专家进行清除，维持系统健康
- 生态意义：鼓励它们快速找到生态位，或被拉回原点重置，维持专家群体的多样性

这两个机制协同工作，形成了一个动态平衡：

- 成熟专家受到保护，其知识得以保留和传承
- 新兴专家获得成长空间，可以探索新的功能领域
- 无效专家被自然淘汰，避免资源浪费
- 整个系统保持持续的自适应能力和稳定的记忆保持

### 生物学诠释：数字免疫应激反应的多层防御体系

MSAPS 机制可以被理解为一个多层防御的数字免疫应激反应 (Digital Immune Stress Response) 系统，其设计灵感来源于生物免疫系统的复杂性和有效性：

#### 第一层：获得性免疫 - 记忆保护与梯度掩蔽

惯性权重与稀疏梯度掩蔽 (SGM) 构成了系统的获得性免疫机制：

- 记忆细胞保护：类似于生物体中对已知病原体的免疫记忆，成熟专家（高门控值）对应付过的任务类型形成了稳定的处理策略。SGM 通过 `w_plasticity = F.relu(1.0 - normalized_gate)` 计算可塑性权重，对成熟专家的梯度进行掩蔽，防止其被新任务的梯度干扰
- 特异性识别：每个专家的门控参数如同抗体的特异性，决定了其对何种输入模式产生响应。高门控值确保这种特异性不被破坏
- 长期记忆保持：通过保护成熟专家的核心参数，系统能够维持对先前学习任务的记忆，实现持续学习而不发生灾难性遗忘

#### 第二层：先天免疫 - 新手专家的快速适应

自适应权重衰减机制对应于先天免疫系统：

- 新手专家清除：对于负门控值的新手专家，强 L2 惩罚如同先天免疫对异常细胞的快速清除机制，防止无效专家占用计算资源
- 快速响应：这种机制不需要复杂的学习过程，能够立即对表现不佳的专家做出反应，维持系统的整体效率
- 生态位竞争：通过淘汰无效专家，为新的、有潜力的专家腾出空间和资源，促进专家群体的自然选择

#### 第三层：干细胞补充 - 专家重置与系统再生

专家重置机制提供了系统的再生能力：

- 死专家检测：通过 `proto_norms < dead_proto_threshold` 识别失去活性的专家，类似于监测到功能丧失的细胞
- 干细胞分化：重新初始化低范数原型如同干细胞分化，为系统注入新的可能性
- 探索-利用平衡：定期的专家重置确保了系统既能利用已有的有效专家，又能探索新的功能空间，避免陷入局部最优

#### 第四层：稳态调节 - 整体系统健康维护

整个 MSAPS 系统通过多重反馈回路维持稳态 (Homeostasis)：

- 门控动态平衡：专家的门控值随着其表现动态调整，形成负反馈调节，防止任何专家垄断资源
- 多样性保持：通过推拉动力学和专家重置，维持专家群体的功能多样性，避免同质化
- 资源优化：自适应的计算资源分配确保每个输入都能激活最适合的专家组合，实现计算效率最大化

这种多层次的免疫隐喻不仅提供了直观的理解框架，更重要的是确保了系统具备：

- 鲁棒性：能够应对各种输入模式和任务变化
- 自适应性：能够持续学习新任务而不遗忘旧知识
- 可扩展性：专家数量可以动态调整以适应复杂度需求
- 可解释性：通过门控值和 Surprise 指标可以直观理解专家的行为和重要性

### Prototype Resident Connection

PRC 在传统的激活值残差连接之外，为原型网络提供了独立的残差流，为网络提供分层增量抽象能力。

在之前的 MSAPS 实现中，我们发现不同类型的 SPL 模块（注意力 QKV、注意力输出、FFN 第一层、FFN 第二层）在功能上存在本质差异：

1. 语义空间异质性：`attn_qkv`处理的是查询-键-值的投影关系，而`ffn_sbl1`处理的是特征空间的非线性变换，它们作用于完全不同的语义空间
2. 梯度流冲突：统一的全局残差连接会导致不同模块的梯度相互干扰，破坏各自的专业化学习进程
3. 信息瓶颈：单层残差无法有效传递复杂的多模态信息，限制了系统的表达能力

当前的解决方案：

- 专业化信息路径：为每个 SPL 模块分配独立的残差流，确保`attn_qkv`的查询投影信息不会与`ffn_sbl1`的特征变换信息混杂
- 梯度隔离机制：通过独立的`proto_transforms`和`proto_layernorms`，每个残差流可以独立调节其梯度的传播路径，避免功能分化过程中的相互干扰

## 延伸：SPL 作为隐式变分自编码器

核心论点: SPL 架构通过其双路信息处理（计算通路 `μ` 与原型通路 `p`）以及 M-SAPS 元学习动力学，在功能上实现了一个隐式的、确定性的变分自编码器 (Implicit & Deterministic VAE)。它在单次前向传播中，通过双优化器架构协同优化了证据下界 (ELBO) 的两个核心组成部分。

### 1. 架构对偶性: Transformer 双路 vs. VAE 编解码器

编码器 (Encoder) → 原型通路 (Prototype Pathway)：由 `proto_weight` (`p`)、SAPS 动力学以及原型残差连接 (PRC) 构成。将输入 `x` 编码为一个稀疏的、上下文感知的潜在表征 `z` (即 `raw_weights`)。PRC 实现了层级化的贝叶斯推断。

解码器 (Decoder) → 计算通路 (Computational Pathway)：由 `mu_weight` (`μ`)、潜在表征 `z` (`raw_weights`) 的掩码作用以及标准的 Transformer 残差连接构成。根据潜在编码 `z`，从一个通用的计算基底 `μ` 中解码出一个专用的、稀疏的计算函数，用于重构或预测目标。

### 动力学对偶性: M-SAPS 元学习 vs. ELBO 优化

变分自编码器通过最大化证据下界 (ELBO) 进行优化：

`log p(x) ≥ ELBO = E_{q(z|x)}[log p(x|z)] - D_{KL}(q(z|x) || p(z))`

重构项 `E[log p(x| z)]` → 主损失函数 `main_loss` (由 `optimizer_main` 优化)：驱动计算核心 `mu_weight` (`μ`) 学习一个能够根据潜在编码 `z` (即 `raw_weights`) 精确重构或预测目标的生成模型。

正则化项 `- D_{KL}(q || p)` → 元学习损失 (`proto_loss` + `gate_loss`) (由 `optimizer_meta` 优化)：通过惊奇度最小化原则，隐式地强制后验分布 `q(z | x)`(由`p`决定) 逼近由模型上一刻动态自组织形成的先验分布`p(z)`。M-SAPS 的自适应权重衰减负责将无用的潜在维度拉回原点，从而实现了对先验的塑造。

### 核心差异与创新：确定性与隐式优化

传统的 VAE 依赖于从编码器定义的分布 `q(z|x)` 中进行随机采样来优化 ELBO。

SPL 架构则另辟蹊径：它通过 `MSAPS` 的确定性梯度，在一个前向传播步骤中同时优化了重构精度（通过 `main_loss` 作用于 `μ`）和潜在空间的正则性（通过 `meta_loss` 作用于 `p` 和 `g`）。这避免了采样带来的方差问题，并实现了更高效的单步推断与学习。

这种"隐式 VAE"的视角为我们提供了一个强大的理论框架，来解释 `Tiny-ONN` 为何能够自组织地学习到可组合的、稀疏的计算结构。

## MoIE & DynSIHA：从微观机制到宏观架构

我们使用 `SPL` 作为核心构建块，来组装更高层次的、完全动态化的 Transformer 组件，实现了从微观神经元级自组织到宏观架构级动态性的跨越。

### MoIE: Mixture of Infinite Experts — 全动态前馈网络

MoIE (Mixture of Infinite Experts) 将标准的 `FFN`（通常由两层 `nn.Linear` 构成）替换为两层 `SPL`，从而将 FFN 从一个固定的非线性变换，升级为了一个两阶段的、内容感知的动态函数合成器：

- 第一阶段：`sbl1` 将隐藏状态映射到扩展维度，实现特征变换和维度提升
- 第二阶段：`sbl2` 将扩展后的特征映射回原始维度，实现信息压缩和输出生成
- 动态专家选择：每个阶段都通过 MSAPS 机制动态选择最适合当前输入的专家组合
- 无限组合空间：通过 `D_ffn` 个基向量的连续线性组合，产生无限的专家组合可能性

这种设计使得 MoIE 能够为每个输入动态实例化一个专用的子网络，实现了计算资源的自适应分配和表达能力的指数级扩展。

### DynSIHA: Dynamic Sparse Infinite-Head Attention — 后多头时代的动态注意力

DynSIHA (Dynamic Sparse Infinite-Head Attention) 抛弃了传统的 Multi-Head 架构，其核心洞察是革命性的：

> 如果 Q、K、V 的投影本身就是通过 `SparseProtoLinear` 动态合成的，那么"多头"这种用于学习不同固定子空间关系的技巧就变得多余了。

DynSIHA 采用单一的 `SPL` 模块一次性地合成出 `Query`、`Key`、`Value`，将注意力机制从一个固定的信息查询系统，升级为一个**端到端可学习的、可编程的动态信息路由与处理系统**：

- **动态投影合成**：根据当前输入的语义内容，动态生成最适合的 Q、K、V 投影矩阵
- **内容感知路由**：每个 token 都能激活不同的专家组合，实现**细粒度的信息处理**
- **消除冗余设计**：不再需要预先定义固定的注意力头，系统能够**自组织**地发现所需的信息处理模式
- **表达能力突破**："无限专家"不是指数量的无限，而是指**有效专家的组合空间是无限的**，远超传统多头注意力的表达能力

## 总结：自组织智能的涌现

通过 SPL with MSAPS，我们将简单的线性层升级为了一个具备**自适应学习率**、能够自发进行**结构涌现**、并能通过**因果固化**实现**持续学习**的微型智能体。这一架构的核心贡献在于：

1. **微观机制创新**：MSAPS 提供了稳定的元学习信号，解决了梯度冲突和灾难性遗忘问题
2. **中观组件突破**：MoIE 和 DynSIHA 实现了真正的动态函数合成，超越了传统静态架构的限制
3. **宏观系统涌现**：通过多层次的专业化分工和协同，整个系统展现出**自组织**、**自适应**、**自进化**的智能特征

这种从**生物启发**到**工程实现**、从**理论设计**到**实践验证**的完整闭环，为构建具有**真正自适应认知能力**的 AI 系统提供了坚实的工程基础。特别是在处理像 ARC 这样的抽象推理任务时，这种能够**动态发现和学习抽象计算规则**的架构展现出了独特的优势和广阔的应用前景。

最终，Tiny-ONN 不仅仅是一个技术架构，更是一种**智能系统设计的哲学**：通过**简单的局部规则**产生**复杂的全局智能**，通过**持续的自适应**实现**永恒的进化**，通过**数字化的免疫机制**确保**鲁棒的生存能力**。这正是通往**通用人工智能**的一条可行路径。
