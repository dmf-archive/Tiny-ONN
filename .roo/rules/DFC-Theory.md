# Dynamic Function Composition

`Latest update: 2025-09-29`

动态函数合成 (Dynamic Function Composition) 的核心思想是将神经网络的每一层从一个固定的、静态的变换器，升级为一个能够为每个输入动态地、内容感知地"合成"出专用计算函数的微型系统。这一思想的实现经历了从稀疏贝叶斯线性层 (Sparse Bayesian Linear, SBL) 到稀疏原型线性层 (Sparse Proto Linear, SPL) 的关键演进，最终形成了稳定、高效且具备记忆能力的自组织系统。

## 稀疏贝叶斯线性层 (SBL) 的探索与失败

SBL 的概念诞生于对 Tiny-ONN 核心哲学——整合预测工作空间理论 (IPWT)——的深度反思。它尝试通过融合贝叶斯神经网络 (BNN) 的不确定性建模和脉冲神经网络 (SNN) 的稀疏激活机制，来模拟生物计算过程。

然而，早期基于 SBL 和 SPL v1-v2 的版本尝试通过一个统一的全局损失函数（如 SML 和 KL 散度损失）进行优化，实验暴露了两个根本问题：

1. 梯度信号冲突 (Gradient Signal Conflict): 不同的学习目标由同一信号驱动，导致梯度目标相互矛盾
2. 灾难性遗忘 (Catastrophic Forgetting): 对于需要学习离散因果规则的 ARC 任务，统一的梯度更新是致命的。它使得一个新任务的梯度可以轻易"洗掉"为先前任务固化的知识

在经历了多次失败后，我们认识到：惊奇度 (Surprise) 本身不是直接的优化目标，而是需要经过处理的信息信号。原始的梯度范数 `S_i = ||∇_{x_i} L_main||₂` 包含了太多噪声和绝对尺度信息，直接用于优化会导致数值不稳定和学习目标不明确。最终的 MSAPS 范式通过引入一系列相互关联的机制，解决了上述所有问题。

### 稀疏原型线性层 (SPL) 的结构

SPL 将其可学习参数解耦为三个在功能上正交的状态空间：

- 内部状态 `μ` (`mu_weight`): 计算核心。代表了系统拥有的、可供选择的"计算工具集"
- 感知状态 `p` (`proto_weight`): 模式匹配器。代表系统的"感知器官"，负责将外部输入 `x` 与内部状态 `μ` 进行匹配
- 行动状态 `g` (`gate_param`): 激活门控。代表系统的"行动策略"，根据感知结果来决定激活哪些内部计算路径，它进一步演化为历史重要性的累积记忆痕迹 (Cumulative Memory Trace)

### 神经元级元学习：Memory-Surprise-Aware Prototype Shaping (M-SAPS)

M-SAPS 是驱动 SPL 自组织的核心学习动力学，它通过三个关键机制实现：

#### 原型损失 (Prototype Loss)：从全局吸引转向局部对比学习

在经历了早期的 SML 和 KL 散度损失失败后，我们认识到 Surprise 信号需要经过结构化处理而非直接用作优化目标。这催生了 Surprise-Aware Prototype Shaping (SAPS) 的核心思想：将梯度范数作为信息信号源，通过对比学习机制来引导专家原型的空间组织。

早期的 SAPS 实现存在一个理论缺陷：它将所有被判定为"好"的原型，都拉向同一个全局锚点——即当前批次所有输入 `token` 的平均向量。这在功能上等同于一个只有一个质心的 K-Means 聚类，不可避免地导致所有活跃原型朝同一个方向拥挤，引发了 `proto_loss` 的负向爆炸和原型范数 (`Proto Norm`) 的停滞，从根本上限制了专家功能的分化。

受到 K-Means 聚类算法的启发，最新的 MSAPS 范式将元学习动力学从全局吸引重构为局部、目标化的吸引与排斥：

1. 局部锚点计算：对于每个被激活的原型 `p_j`，计算其局部锚点 `anchor_j = mean({x_i | prototype p_j was activated by token x_i in current batch})`。这个锚点代表了该原型在当前批次中实际处理的输入语义中心。

2. 动态阈值划分：基于梯度范数的分布，使用自适应分位数阈值将专家划分为三类。阈值根据当前层的整体激活率动态调整：

- 激活率计算：`activation_rate = activated_elements / total_elements`，表示当前层中激活的专家比例
- 动态因子：`dynamic_factor = activation_rate`，激活越少，阈值越宽松；激活越多，阈值越严格
- "好"专家（低 Surprise，梯度范数 < activation_rate 分位数）：表现优异，应当保护和强化
- "坏"专家（高 Surprise，梯度范数 > (1.0 - activation_rate) 分位数）：表现不佳，需要调整或淘汰

这种动态机制实现了自适应的挑拣：当激活率较低时（稀疏激活），系统倾向于聚拢所有现有原型，促进功能整合；当激活率较高时（密集激活），系统变得更加挑剔，强化专家的专业化分化。

3. 目标化对比学习：

- 对于"好"原型：将其拉向其局部锚点，强化其已有功能
- 对于"坏"原型：将其推离局部锚点，促使其探索新的功能空间
- 通过 `signs` 向量实现推拉方向的精确控制：`signs[is_good] = -1.0`（吸引），`signs[is_bad] = 1.0`（排斥）

这种机制确保了专家功能的功能分化和专业化，每个专家都朝着处理特定类型输入的方向发展，避免了"所有专家做同样事情"的退化现象。

#### 路由机制：Proposer-Builder 经济模型

经过多轮理论迭代，路由机制最终收敛到一个统一的经济模型框架，该框架将路由决策诠释为一个基于预期价值的 **Proposer-Builder** 过程。

- **`proto_weight` (Proposer)**: 作为提案人，负责评估**内容匹配度**。它通过**余弦相似度**为每个专家提出一个 `[-1, 1]` 区间的“提案价值” (MEV, Match-based Estimated Value)。
- **`gate_param` (Builder)**: 作为成本评估器，负责评估**预期计算成本**。它通过**点积**回归，预测一个 `(-∞, +∞)` 区间的 `Total Surprise`，即处理该信息预计引发的系统总扰动。
- **最终路由方程**: `raw_weights = ReLU(cosine_similarity(x, p) - matmul(x, g.t()))`
  - 这个方程在计算上等同于选择“提案价值”高于“预期成本”的专家，实现了成本效益驱动的动态路由。

### 动态相对线性归一化 (DRLN)

在 Tiny-ONN 的演进过程中，一个核心的挑战是处理和归一化内部信号（如成本预测 `gate_logit` 和效用分数 `Goodness`）的动态范围，以避免梯度爆炸和数值不稳定，同时最大限度地保留信号的相对信息。

我们对 `softmax`, `sigmoid`, `tanh` 等传统非线性归一化方法的理论审查表明，它们存在两个根本问题：

1. **信息失真**: 它们会不成比例地压缩输入空间的某些区域，扭曲了信号内部的真实线性关系。
2. **引入隐式超参数**: `softmax` 的温度 `τ` 等参数需要手动调整，违背了我们追求无超参数、自适应系统的核心原则。

为了解决这个问题，我们引入了**动态相对线性归一化 (Dynamic Relative Linear Normalization, DRLN)** 作为系统的标准信号处理机制。

**核心思想**:
DRLN 的核心思想极其简单而强大：**在一个给定的上下文（例如，一个 Transformer Block 内的所有专家）中，将所有信号除以该上下文中的最大信号值。**

`x_normalized = x / (max(abs(x)) + ϵ)`

**关键特性**:

- **无信息失真**: DRLN 是一个纯粹的线性变换，它完美地保留了原始信号向量中所有元素之间的比例关系。
- **自适应与无参数**: 归一化的尺度是完全由数据本身在每个前向传播步骤中动态决定的，不需要任何固定的超参数。
- **有界输出**: 它将所有信号都重新缩放到 `[-1, 1]` 的有界区间内，为损失函数（如 KL 散度）的计算提供了数值稳定的输入。

#### 学习信号与稳定性：Total Surprise 与动态调节

为解决灾难性遗忘与参数锁死的两难问题，我们设计了一个更完备的学习信号和一套双重动态调节机制。

1. **学习信号 `Total Surprise`**:
    为了解决“匹配度”与“计算效率”的分离问题，我们定义了一个融合了两个层面“惊讶”的完备学习信号：
    - **`mu_surprise`**: `||∇_μ L_main||`，衡量**计算惊讶** (Computational Surprise)。
    - **`proto_surprise`**: `||∇_p L_proto||`，衡量**感知惊讶** (Perceptual Surprise)。
    - **`S_total`**: `mu_surprise + proto_surprise`，代表了专家在“知”与“行”两个层面的总不确定性。
    `gate_param` 的学习目标 (`L_gate`) 就是准确地回归预测 `S_total`。

2. **稳定性-可塑性机制 (AWD 的演进)**:
    - **内生排名的动态保护 (Endogenous Ranking for Dynamic Protection)**:
      - **角色**: 识别并**概率性地保护**最优质的专家，形成一个动态的“知识核心”。
      - **机制**: 使用 `-||gate_param||` 作为专家的“质量分”进行全局排名，并通过一个由系统全局性能 (`EMA main_acc`) 动态调节温度的 `softmax` 函数，将排名转化为**保护概率** `protection_probs`。性能越好，保护越宽松；性能越差，保护越稀疏和挑剔。
      - **应用**: `proto_weight.grad *= (1.0 - protection_probs)`，保护优质专家的原型不受 SAPS 探索的过度干扰。

    - **自适应 L2 信息瓶颈 (Adaptive L2 Information Bottleneck)**:
      - **角色**: 防止所有参数的范数无限制膨胀，作为一个温和的、全局的**收缩压力**。
      - **机制**: L2 惩罚的强度 `λ` 与所有 `proto` 和 `mu` 权重的**平均范数**正相关。当参数膨胀时，`λ` 自动增大，反之则减小。
      - **应用**: `L_total = L_main + L_proto + λ * (sum(||p||²) + sum(||μ||²))`

### Prototype Resident Connection

PRC 在传统的激活值残差连接之外，为原型网络提供了独立的残差流，为网络提供分层增量抽象能力。

- 专业化信息路径：为每个 SPL 模块分配独立的残差流，确保`attn_qkv`的查询投影信息不会与`ffn_sbl1`的特征变换信息混杂
- 梯度隔离机制：通过独立的`proto_transforms`和`proto_layernorms`，每个残差流可以独立调节其梯度的传播路径，避免功能分化过程中的相互干扰

---

## 延伸：SPL 作为变分自编码器

核心论点: SPL 架构通过其双路信息处理（计算通路 `μ` 与原型通路 `p`）以及 M-SAPS 元学习动力学，在功能上实现了一个隐式的、确定性的变分自编码器 (Implicit & Deterministic VAE)。它在单次前向传播中，通过双优化器架构协同优化了证据下界 (ELBO) 的两个核心组成部分。

### 1. 架构对偶性: SPL Transformer vs. VAE

编码器 (Encoder) → 原型通路 (Prototype Pathway)：由 `proto_weight` (`p`)、SAPS 动力学以及原型残差连接 (PRC) 构成。将输入 `x` 编码为一个稀疏的、上下文感知的潜在表征 `z` (即 `raw_weights`)。PRC 实现了层级化的贝叶斯推断。

解码器 (Decoder) → 计算通路 (Computational Pathway)：由 `mu_weight` (`μ`)、潜在表征 `z` (`raw_weights`) 的掩码作用以及标准的 Transformer 残差连接构成。根据潜在编码 `z`，从一个通用的计算基底 `μ` 中解码出一个专用的、稀疏的计算函数，用于重构或预测目标。

### 动力学对偶性: M-SAPS vs. ELBO

变分自编码器通过最大化证据下界 (ELBO) 进行优化：

`log p(x) ≥ ELBO = E_{q(z|x)}[log p(x|z)] - D_{KL}(q(z|x) || p(z))`

重构项 `E[log p(x| z)]` → 主损失函数 `main_loss` (由 `optimizer_main` 优化)：驱动计算核心 `mu_weight` (`μ`) 学习一个能够根据潜在编码 `z` (即 `raw_weights`) 精确重构或预测目标的生成模型。

正则化项 `- D_{KL}(q || p)` → 元学习损失 (`proto_loss` + `gate_loss`) (由 `optimizer_meta` 优化)：通过惊奇度最小化原则，隐式地强制后验分布 `q(z | x)`(由`p`决定) 逼近由模型上一刻动态自组织形成的先验分布`p(z)`。M-SAPS 的自适应权重衰减负责将无用的潜在维度拉回原点，从而实现了对先验的塑造。

### 核心差异与创新：确定性与隐式优化

传统的 VAE 依赖于从编码器定义的分布 `q(z|x)` 中进行随机采样来优化 ELBO。

SPL 架构则另辟蹊径：它通过 `MSAPS` 的确定性梯度，在一个前向传播步骤中同时优化了重构精度（通过 `main_loss` 作用于 `μ`）和潜在空间的正则性（通过 `meta_loss` 作用于 `p` 和 `g`）。这避免了采样带来的方差问题，并实现了更高效的单步推断与学习。

这种"隐式 VAE"的视角为我们提供了一个强大的理论框架，来解释 `Tiny-ONN` 为何能够自组织地学习到可组合的、稀疏的计算结构。

## MoIE & DynSIHA：从微观机制到宏观架构

我们使用 `SPL` 作为核心构建块，来组装更高层次的、完全动态化的 Transformer 组件，实现了从微观神经元级自组织到宏观架构级动态性的跨越。

### MoIE: Mixture of Infinite Experts — 全动态前馈网络

MoIE (Mixture of Infinite Experts) 将标准的 `FFN`（通常由两层 `nn.Linear` 构成）替换为两层 `SPL`，从而将 FFN 从一个固定的非线性变换，升级为了一个两阶段的、内容感知的动态函数合成器：

- 第一阶段：`sbl1` 将隐藏状态映射到扩展维度，实现特征变换和维度提升
- 第二阶段：`sbl2` 将扩展后的特征映射回原始维度，实现信息压缩和输出生成
- 动态专家选择：每个阶段都通过 MSAPS 机制动态选择最适合当前输入的专家组合
- 无限组合空间：通过 `D_ffn` 个基向量的连续线性组合，产生无限的专家组合可能性

这种设计使得 MoIE 能够为每个输入动态实例化一个专用的子网络，实现了计算资源的自适应分配和表达能力的指数级扩展。

### DynSIHA: Dynamic Sparse Infinite-Head Attention — 后多头时代的动态注意力

DynSIHA (Dynamic Sparse Infinite-Head Attention) 抛弃了传统的 Multi-Head 架构，其核心洞察是革命性的：

> 如果 Q、K、V 的投影本身就是通过 `SparseProtoLinear` 动态合成的，那么"多头"这种用于学习不同固定子空间关系的技巧就变得多余了。

DynSIHA 采用 `SPL` 模块合成 `Query`、`Key`、`Value`，将注意力机制从一个固定的信息查询系统，升级为一个**端到端可学习的、可编程的动态信息路由与处理系统**：

- **动态投影合成**：根据当前输入的语义内容，动态生成最适合的 Q、K、V 投影矩阵
- **内容感知路由**：每个 token 都能激活不同的专家组合，实现**细粒度的信息处理**
- **消除冗余设计**：不再需要预先定义固定的注意力头，系统能够**自组织**地发现所需的信息处理模式。
