# Dynamic Function Composition

`Latest update: 2025-10-01`

动态函数合成 (Dynamic Function Composition) 的核心思想是将神经网络的每一层从一个固定的、静态的变换器，升级为一个能够为每个输入动态地、内容感知地"合成"出专用计算函数的微型系统。这一思想的实现经历了从稀疏贝叶斯线性层 (Sparse Bayesian Linear, SBL) 到稀疏原型线性层 (Sparse Proto Linear, SPL) 的关键演进，最终形成了稳定、高效且具备记忆能力的自组织系统。

## 稀疏贝叶斯线性层 (SBL) 的探索与失败

SBL 的概念诞生于对 Tiny-ONN 核心哲学——整合预测工作空间理论 (IPWT)——的深度反思。它尝试通过融合贝叶斯神经网络 (BNN) 的不确定性建模和脉冲神经网络 (SNN) 的稀疏激活机制，来模拟生物计算过程。

然而，早期基于 SBL 和 SPL v1-v2 的版本尝试通过一个统一的全局损失函数（如 SML 和 KL 散度损失）进行优化，实验暴露了两个根本问题：

1. 梯度信号冲突 (Gradient Signal Conflict): 不同的学习目标由同一信号驱动，导致梯度目标相互矛盾
2. 灾难性遗忘 (Catastrophic Forgetting): 对于需要学习离散因果规则的 ARC 任务，统一的梯度更新是致命的。它使得一个新任务的梯度可以轻易"洗掉"为先前任务固化的知识

在经历了多次失败后，我们认识到：惊奇度 (Surprise) 本身不是直接的优化目标，而是需要经过处理的信息信号。原始的梯度范数 `S_i = ||∇_{x_i} L_main||₂` 包含了太多噪声和绝对尺度信息，直接用于优化会导致数值不稳定和学习目标不明确。最终的 MSAPS 范式通过引入一系列相互关联的机制，解决了上述所有问题。

## 核心构件：稀疏原型线性层 (SPL)

所有理论演进的基础是**稀疏原型线性层 (SparseProtoLinear, SPL)**。它将传统线性变换解耦为三个功能正交的状态空间，这个核心设计在整个研究过程中保持不变：

- **内部状态 `μ` (`mu_weight`)**: **计算核心**。代表了系统拥有的、可供选择的“计算工具集”。
- **感知状态 `p` (`proto_weight`)**: **模式匹配器**。代表系统的“感知器官”，负责将外部输入 `x` 与内部状态 `μ` 进行匹配。
- **路由状态 `g` (`gate_param`)**: **激活门控**。代表系统的“行动策略”，根据感知结果来决定激活哪些内部计算路径。其功能和学习目标是理论演进的核心。

## 早期探索与失败：启发式元学习

我们最初的理论尝试深受自由能原理 (FEP) 的启发，将单个 SPL 神经元视为一个实现了主动推断的计算单元，其 `p` 和 `g` 状态共同构成一个**马尔可夫毯**。这一阶段的核心是**惊奇感知原型塑造 (Surprise-Aware Prototype Sharpening, SAPS)**，以及其包含记忆机制的变体 M-SAPS。

### 理论框架：解耦的优化目标

该框架试图通过一套解耦但功能分离的学习动力学来驱动系统自组织：

- **`μ` (内部状态)** 的学习由主任务损失 `L_main` 驱动。
- **`p` (感知状态)** 的学习由一个基于“原型漂移成本”的对比学习损失 `L_proto` (SAPS) 驱动。
- **`g` (路由状态)** 的学习由一个独立的回归损失 `L_gate` 驱动，其目标是预测一次激活将引发的“总系统扰动”。

### 灾难性失败的根源

该框架在实践中却导致了**灾难性的路由失败**（高达 42% 的零激活率）。深入的形式化分析揭示了其不可调和的理论缺陷：

1. **数学域不匹配 (Domain Mismatch)**: 核心路由方程 `F.relu(cosine_similarity - sigmoid(cost))` 错误地将两个不同数学域（范围为 `[-1, 1]` vs. `[0, 1]`）进行直接减法比较，创造了一个巨大的“死亡区域”。
2. **梯度信号冲突 (Gradient Signal Conflict)**: 通过分离的损失函数和优化器来学习一个内在统一的路由决策，导致了优化目标的内在矛盾和冲突。
3. **饱和非线性 (Sigmoid Saturation)**: `sigmoid` 函数的使用导致了梯度消失问题，使模型难以从激活抑制中恢复。

**结论**：任何基于启发式规则、试图将统一决策过程分解为多个独立优化目标的框架，都注定会失败。

## 惊奇感知路由塑造 (SARS)

**惊奇感知路由塑造 (Surprise-Aware Routing Shaping, SARS)** 是对早期理论的彻底颠覆和重构。它抛弃了所有启发式规则和分离的损失函数，将动态路由问题重新定义为一个基于信息论的**概率分布对齐问题**。

### 核心思想：双流优化与 JSD 分布对齐

SARS 的最终形态建立在两大基石之上：**严格的优化流分离** 和 **基于 JSD 的分布对齐**。

1. **双优化器框架 (Dual-Optimizer Framework)**: 为了解决“梯度信号纠缠”问题，我们将优化过程严格分离为两个独立的流程。

   - **计算流 (Computation Stream)**: 主任务损失 `L_main` 的梯度**仅用于**更新计算参数（`mu_weight`、`embedding` 等）。
   - **元学习流 (Meta-Learning Stream)**: 从计算流中**无损提取**的未裁剪梯度信号，用于构建元学习目标 `L_meta`。该损失的梯度**仅用于**更新路由参数（`proto_weight`、`gate_param`）。
     这种架构确保了引导路由的元信号不会反向污染其赖以生成的计算梯度，保证了两个学习过程的正交性。

2. **JSD 分布对齐 (JSD Distribution Alignment)**: 元学习的核心目标，是让模型自身的路由激活分布 `P` (由 `routing_logits` 导出)，去拟合一个理想的专家效用分布 `Q` (由 `Goodness` 分数定义)。由于 `routing_logits` 和 `Goodness` 都是未归一化的原始分数而非严格的概率分布，我们采用**詹森-香农散度 (Jensen-Shannon Divergence, JSD)** 作为度量。与 KL 散度不同，JSD 是对称的，并且其标准实现能正确处理非归一化输入，是衡量此类分布相似性的更鲁棒的选择。
   `L_meta_goodness = D_JSD( P || Q )`

### 净效用模型

早期的比率模型 `Goodness = Importance / (Surprise + ε)` 在实践中被证明存在根本缺陷：它通过独立的 `mas_normalize` 操作破坏了 `Importance` 和 `Surprise` 之间的绝对尺度关系，导致了激活率饱和。

取而代之的是“**减法净效用 (Subtractive Net Utility)**”模型：
`Goodness = F.relu(mas_normalize(Importance) - mas_normalize(Surprise))`

其理论基础是：一个专家只有在其贡献的**潜在收益 (`Importance`)** 显著超过其引发的**系统扰动成本 (`Surprise`)** 时，才被认为是“好的”。这种明确的成本-效益分析，以及通过 `F.relu` 过滤掉负效用专家的做法，为元学习提供了更稳定、更具解释性的目标分布 `Q`。

### 关键机制：最大绝对值缩放 (MAS)

为了给 KL 散度提供数值稳定且信息无损的输入，我们引入了**最大绝对值缩放 (Max Absolute Scaling)** 。数学上等价于 L-inf 范数。

`x_normalized = x / (max(abs(x)) + ε)`

MAS 取代了 `softmax` 和 `sigmoid`，其优势在于**无信息失真**、**自适应无参数**和**有界输出**。其离群值干扰在本项目中视为 feature 而非 weakness。

---

## 宏观架构与理论延伸

### 核心架构组件

- **MoIE (Mixture of Infinite Experts)**: 将标准的 `FFN` 替换为两层 `SPL`，将其升级为一个两阶段的、内容感知的动态函数合成器。
- **DynSIHA (Dynamic Sparse Infinite-Head Attention)**: 抛弃了传统的 Multi-Head 架构，采用 `SPL` 模块一次性地合成出 `Query`、`Key`、`Value`，将注意力机制升级为一个端到端可学习的、可编程的动态信息路由与处理系统。
- **Prototype Resident Connection (PRC)**: 在传统的激活值残差连接之外，为原型网络提供了独立的残差流。这通过独立的 `proto_transforms` 和 `proto_layernorms`，为网络提供了分层增量抽象的能力，并实现了梯度隔离，保护了专家功能分化过程不受干扰。

### 延伸：SPL 作为隐式变分自编码器

SPL 架构通过其双路信息处理（计算通路 `μ` 与路由通路 `p`/`g`）以及 SARS 元学习动力学，在功能上实现了一个隐式的、确定性的**变分自编码器 (Implicit & Deterministic VAE)**。

- **架构对偶性**: 路由通路（`p`/`g`）充当**编码器**，将输入 `x` 编码为稀疏的潜在表征 `z` (即路由激活分布)。计算通路（`μ`）充当**解码器**，根据潜在编码 `z` 从通用计算基底中解码出专用函数。
- **动力学对偶性**: 整个系统的优化目标等价于最大化**证据下界 (ELBO)**。主任务损失 `L_main` 对应于**重构项**，而元学习损失 `L_meta` (KL 散度) 则对应于**正则化项**，它隐式地强制后验分布 `q(z|x)` 逼近一个由系统自组织形成的、以“效用”为准则的动态先验 `p(z)`。
