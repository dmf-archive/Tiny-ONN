# Dynamic Function Composition

`Latest update: 2025-09-21`

动态函数合成 (Dynamic Function Composition) 的核心思想是将神经网络的每一层从一个固定的、静态的变换器，升级为一个能够为每个输入动态地、内容感知地"合成"出专用计算函数的微型系统。这一思想的实现经历了从稀疏贝叶斯线性层 (Sparse Bayesian Linear, SBL) 到稀疏原型线性层 (Sparse Proto Linear, SPL) 的关键演进，最终形成了稳定、高效且具备记忆能力的自组织系统。

## 稀疏贝叶斯线性层 (SBL) 的探索与失败

SBL 的概念诞生于对 Tiny-ONN 核心哲学——整合预测工作空间理论 (IPWT)——的深度反思。它尝试通过融合贝叶斯神经网络 (BNN) 的不确定性建模和脉冲神经网络 (SNN) 的稀疏激活机制，来模拟生物计算过程。

然而，早期基于 SBL 和 SPL v1-v2 的版本尝试通过一个统一的全局损失函数（如 SML 和 KL 散度损失）进行优化，实验暴露了两个根本问题：

1. 梯度信号冲突 (Gradient Signal Conflict): 不同的学习目标由同一信号驱动，导致梯度目标相互矛盾
2. 灾难性遗忘 (Catastrophic Forgetting): 对于需要学习离散因果规则的 ARC 任务，统一的梯度更新是致命的。它使得一个新任务的梯度可以轻易"洗掉"为先前任务固化的知识

在经历了多次失败后，我们认识到：惊奇度 (Surprise) 本身不是直接的优化目标，而是需要经过处理的信息信号。原始的梯度范数 `S_i = ||∇_{x_i} L_main||₂` 包含了太多噪声和绝对尺度信息，直接用于优化会导致数值不稳定和学习目标不明确。最终的 MSAPS 范式通过引入一系列相互关联的机制，解决了上述所有问题。

### 稀疏原型线性层 (SPL) 的结构

SPL 将其可学习参数解耦为三个在功能上正交的状态空间：

- 内部状态 `μ` (`mu_weight`): 计算核心。代表了系统拥有的、可供选择的"计算工具集"
- 感知状态 `p` (`proto_weight`): 模式匹配器。代表系统的"感知器官"，负责将外部输入 `x` 与内部状态 `μ` 进行匹配
- 行动状态 `g` (`gate_param`): 激活门控。代表系统的"行动策略"，根据感知结果来决定激活哪些内部计算路径，它进一步演化为历史重要性的累积记忆痕迹 (Cumulative Memory Trace)

### 神经元级元学习：Memory-Surprise-Aware Prototype Shaping (M-SAPS)

M-SAPS 是驱动 SPL 自组织的核心学习动力学，它通过三个关键机制实现：

#### 原型损失 (Prototype Loss)：从全局吸引转向局部对比学习

在经历了早期的 SML 和 KL 散度损失失败后，我们认识到 Surprise 信号需要经过结构化处理而非直接用作优化目标。这催生了 Surprise-Aware Prototype Shaping (SAPS) 的核心思想：将梯度范数作为信息信号源，通过对比学习机制来引导专家原型的空间组织。

早期的 SAPS 实现存在一个理论缺陷：它将所有被判定为"好"的原型，都拉向同一个全局锚点——即当前批次所有输入 `token` 的平均向量。这在功能上等同于一个只有一个质心的 K-Means 聚类，不可避免地导致所有活跃原型朝同一个方向拥挤，引发了 `proto_loss` 的负向爆炸和原型范数 (`Proto Norm`) 的停滞，从根本上限制了专家功能的分化。

受到 K-Means 聚类算法的启发，最新的 MSAPS 范式将元学习动力学从全局吸引重构为局部、目标化的吸引与排斥：

1. 局部锚点计算：对于每个被激活的原型 `p_j`，计算其局部锚点 `anchor_j = mean({x_i | prototype p_j was activated by token x_i in current batch})`。这个锚点代表了该原型在当前批次中实际处理的输入语义中心。

2. 动态阈值划分：基于梯度范数的分布，使用自适应分位数阈值将专家划分为三类。阈值根据当前层的整体激活率动态调整：

- 激活率计算：`activation_rate = activated_elements / total_elements`，表示当前层中激活的专家比例
- 动态因子：`dynamic_factor = activation_rate`，激活越少，阈值越宽松；激活越多，阈值越严格
- "好"专家（低 Surprise，梯度范数 < activation_rate 分位数）：表现优异，应当保护和强化
- "坏"专家（高 Surprise，梯度范数 > (1.0 - activation_rate) 分位数）：表现不佳，需要调整或淘汰

这种动态机制实现了自适应的挑拣：当激活率较低时（稀疏激活），系统倾向于聚拢所有现有原型，促进功能整合；当激活率较高时（密集激活），系统变得更加挑剔，强化专家的专业化分化。

3. 目标化对比学习：

- 对于"好"原型：将其拉向其局部锚点，强化其已有功能
- 对于"坏"原型：将其推离局部锚点，促使其探索新的功能空间
- 通过 `signs` 向量实现推拉方向的精确控制：`signs[is_good] = -1.0`（吸引），`signs[is_bad] = 1.0`（排斥）

这种机制确保了专家功能的功能分化和专业化，每个专家都朝着处理特定类型输入的方向发展，避免了"所有专家做同样事情"的退化现象。

#### Gate Loss：自适应可塑性与价值固化

经过多轮理论迭代，`gate_loss` 的设计最终收敛到一个极致简洁且理论完备的形式，它将专家的价值 (`gate_param`) 与系统的外部表现 (`main_loss`) 和内部稳定 (`Surprise`) 直接挂钩。

其定义如下：

`L_gate = MSE(g_i, g_i*)`

其中，目标门控值 g 为：

`g_i* = (1.0 - L_main) - |S_i|`

- `g_i`: 第 `i` 个专家的门控参数（累积价值记忆）。
- `S_i`: 第 `i` 个专家的"惊奇度"，即 ‖∇_μ_i L_main‖₂，衡量处理当前任务对该专家计算核心 `μ` 的扰动程度。
- `L_main`: 当前任务的全局主损失，反映了系统的外部表现。

这个公式实现了几个关键的动态机制：

1. 动态可塑性上限: `gate` 的实际上限 G_max 被动态设定为 `1.0 - L_main`。当模型在任务上表现不佳（`L_main` 增大）时，所有受此影响的专家的 `gate` 上限会被相应降低，促使它们进入更易于调整的状态。由于 `L_main` 始终大于零，模型将永远不会完全失去可塑性。

2. 价值与稳定性的协同: 目标 `g*` 旨在奖励那些内部稳定（低 `Surprise`）的专家，但其上限受到模型整体表现 `G_max` 的制约。只有当模型在任务上表现出色时，一个专家才能通过持续的稳定贡献获得极高的 `gate` 值。

3. 休眠与淘汰机制: 与当前任务无关的专家，由于其 `Surprise` 为零且 `gate_loss` 也为零，能够保持其原有的高 `gate` 值（进入休眠状态）。相反，持续表现不佳（高 `Surprise`）的专家，其 `g*` 会被负向拉动，最终被以价值为导向的回收机制淘汰（进入隐退状态）。

4. 任务局域性: `L_main` 和 `S_i` 的计算均仅基于当前被激活的专家。因此，这些调节信号具有任务局域性，休眠的专家不受其影响，其固有的知识得以保留。

#### 自适应权重衰减 (Adaptive Weight Decay)

可以被理解为一个多层防御的数字免疫应激反应 (Digital Immune Stress Response) 系统，其设计灵感来源于生物免疫系统的复杂性和有效性：

- _惯性权重 (Inertia Weight):_ `W_I(g) = 1 - ReLU(g) / (|g| + ε)`
  - 对于成熟专家（`g >> 0`），`W_I ≈ 0` 通过稀疏梯度掩蔽 (SGM) 抑制 `μ_weight` 和 `μ_bias` 的梯度，形成获得性免疫保护机制。`ReLU(g)` 确保仅正值门控触发抑制，`ε` 防止数值奇点。
- _衰减权重 (Decay Weight):_ `W_D(g) = ReLU(-g) / (|g| + ε)`
  - 对于无效专家（`g ≪ 0`），`W_D ≈ 1` 通过 L2 惩罚驱动权重趋零，实现先天免疫清除。该机制维持专家群体多样性，促使系统持续探索功能空间。
- _专家重置 (Expert Reinitialize):_
  - 基于 `gate_param` 的淘汰机制：当 `gate_param < threshold` 时触发参数重初始化。此干细胞分化过程确保仅价值耗散专家被重置，维持探索-利用平衡。

### Prototype Resident Connection

PRC 在传统的激活值残差连接之外，为原型网络提供了独立的残差流，为网络提供分层增量抽象能力。

- 专业化信息路径：为每个 SPL 模块分配独立的残差流，确保`attn_qkv`的查询投影信息不会与`ffn_sbl1`的特征变换信息混杂
- 梯度隔离机制：通过独立的`proto_transforms`和`proto_layernorms`，每个残差流可以独立调节其梯度的传播路径，避免功能分化过程中的相互干扰

## Soft-M-SAPS: 解锁组合路由

M-SAPS 的核心架构（如双优化器、梯度分离）是健全的，但其具体的路由和元学习公式被证明在 ARC 任务上是不稳定的。Soft-M-SAPS 是对这些核心公式的一次理论重构，旨在提供更稳定和理论完备的动力学。

### 路由机制：内容相关性 vs. 绝对成本

为解决 M-SAPS 路由机制中硬门控导致的原型锁死问题，我们引入了新的路由公式：
`final_weights = ReLU(softmax(cos(x, p)) - g)`

- **`softmax(cos(x, p))`**: 通过 Softmax 提供了"软"的内容相关性评估，允许梯度流向所有潜在专家，以供元学习算法进行评估。
- **`g`**: 直接用作专家的平均历史成本（一个 `[0,1]` 区间的值），作为激活阈值。
- **`ReLU(...)`**: 最终通过比较相对的内容相关性和平均的历史成本，来实现稀疏激活。

### 元学习：成本记录与原型塑造

我们为马尔可夫毯 (`p`,`g`) 设计了新的更新规则，依然由独立的 `optimizer_meta` 驱动。

- **`L_gate` (成本记录)**: 新的损失函数将 `g` 训练为历史相对扰动程度的 EMA 平滑记录：
  `L_gate = MSE(g, softmax(S).detach())`
  其中 `g` 的语义为"成本"（0=好, 1=差），并在更新后被 clamp 到 `[0,1]`。
- **`L_proto` (几何判别原型塑造)**: 与旧的局部 SAPS 机制不同，新的 `L_proto` 采用**全局几何判别**策略。其核心思想是最大化“好”输入与“坏”输入在嵌入空间中的可分性，从而训练原型层成为一个在线的线性判别器。
    1. **全局输入分区**：根据专家分区（`P_good`, `P_bad`），将当前批次所有输入 `token` 划分为两个全局集合：`X_good`（激活了至少一个好专家）和 `X_bad`（激活了至少一个坏专家）。
    2. **全局质心计算**：计算两个点云的**质心 (Centroid)**，作为其分布一阶矩的估计：
        - `μ_good = mean(X_good)`
        - `μ_bad = mean(X_bad)`
    3. **判别式对比损失**：利用全局质心作为正负样本锚点，通过对比学习来训练原型：
        `L_proto = Σ_{pᵢ ∈ P_good} [ c(pᵢ, μ_bad) - c(pᵢ, μ_good) ] + Σ_{pⱼ ∈ P_bad} c(pⱼ, μ_good)`
        其中 `c(·, ·)` 为余弦相似度。该损失旨在使所有“好”原型 `pᵢ` 靠近 `μ_good` 并远离 `μ_bad`，同时将所有“坏”原型 `pⱼ` 推离 `μ_good`，从而加速专家功能的分化，并提供一个更稳定、更具全局视野的训练信号。

### 稳定性机制：自适应权重衰减修正

为适应 `g` 的新语义（`[0,1]`），自适应权重衰减的公式也进行了相应修正：

- **惯性权重 (SGM)**: `μ.grad *= g`。低成本（`g`≈0）专家的梯度被大幅削减，从而被保护。
- **衰减权重**: `L2_penalty = g * (weight**2)`。高成本（`g`≈1）专家的权重被推向零。
- **专家重置**: `if g > threshold: reset_expert()`。

---

## 延伸：SPL 作为变分自编码器

核心论点: SPL 架构通过其双路信息处理（计算通路 `μ` 与原型通路 `p`）以及 M-SAPS 元学习动力学，在功能上实现了一个隐式的、确定性的变分自编码器 (Implicit & Deterministic VAE)。它在单次前向传播中，通过双优化器架构协同优化了证据下界 (ELBO) 的两个核心组成部分。

### 1. 架构对偶性: SPL Transformer vs. VAE

编码器 (Encoder) → 原型通路 (Prototype Pathway)：由 `proto_weight` (`p`)、SAPS 动力学以及原型残差连接 (PRC) 构成。将输入 `x` 编码为一个稀疏的、上下文感知的潜在表征 `z` (即 `raw_weights`)。PRC 实现了层级化的贝叶斯推断。

解码器 (Decoder) → 计算通路 (Computational Pathway)：由 `mu_weight` (`μ`)、潜在表征 `z` (`raw_weights`) 的掩码作用以及标准的 Transformer 残差连接构成。根据潜在编码 `z`，从一个通用的计算基底 `μ` 中解码出一个专用的、稀疏的计算函数，用于重构或预测目标。

### 动力学对偶性: M-SAPS vs. ELBO

变分自编码器通过最大化证据下界 (ELBO) 进行优化：

`log p(x) ≥ ELBO = E_{q(z|x)}[log p(x|z)] - D_{KL}(q(z|x) || p(z))`

重构项 `E[log p(x| z)]` → 主损失函数 `main_loss` (由 `optimizer_main` 优化)：驱动计算核心 `mu_weight` (`μ`) 学习一个能够根据潜在编码 `z` (即 `raw_weights`) 精确重构或预测目标的生成模型。

正则化项 `- D_{KL}(q || p)` → 元学习损失 (`proto_loss` + `gate_loss`) (由 `optimizer_meta` 优化)：通过惊奇度最小化原则，隐式地强制后验分布 `q(z | x)`(由`p`决定) 逼近由模型上一刻动态自组织形成的先验分布`p(z)`。M-SAPS 的自适应权重衰减负责将无用的潜在维度拉回原点，从而实现了对先验的塑造。

### 核心差异与创新：确定性与隐式优化

传统的 VAE 依赖于从编码器定义的分布 `q(z|x)` 中进行随机采样来优化 ELBO。

SPL 架构则另辟蹊径：它通过 `MSAPS` 的确定性梯度，在一个前向传播步骤中同时优化了重构精度（通过 `main_loss` 作用于 `μ`）和潜在空间的正则性（通过 `meta_loss` 作用于 `p` 和 `g`）。这避免了采样带来的方差问题，并实现了更高效的单步推断与学习。

这种"隐式 VAE"的视角为我们提供了一个强大的理论框架，来解释 `Tiny-ONN` 为何能够自组织地学习到可组合的、稀疏的计算结构。

## MoIE & DynSIHA：从微观机制到宏观架构

我们使用 `SPL` 作为核心构建块，来组装更高层次的、完全动态化的 Transformer 组件，实现了从微观神经元级自组织到宏观架构级动态性的跨越。

### MoIE: Mixture of Infinite Experts — 全动态前馈网络

MoIE (Mixture of Infinite Experts) 将标准的 `FFN`（通常由两层 `nn.Linear` 构成）替换为两层 `SPL`，从而将 FFN 从一个固定的非线性变换，升级为了一个两阶段的、内容感知的动态函数合成器：

- 第一阶段：`sbl1` 将隐藏状态映射到扩展维度，实现特征变换和维度提升
- 第二阶段：`sbl2` 将扩展后的特征映射回原始维度，实现信息压缩和输出生成
- 动态专家选择：每个阶段都通过 MSAPS 机制动态选择最适合当前输入的专家组合
- 无限组合空间：通过 `D_ffn` 个基向量的连续线性组合，产生无限的专家组合可能性

这种设计使得 MoIE 能够为每个输入动态实例化一个专用的子网络，实现了计算资源的自适应分配和表达能力的指数级扩展。

### DynSIHA: Dynamic Sparse Infinite-Head Attention — 后多头时代的动态注意力

DynSIHA (Dynamic Sparse Infinite-Head Attention) 抛弃了传统的 Multi-Head 架构，其核心洞察是革命性的：

> 如果 Q、K、V 的投影本身就是通过 `SparseProtoLinear` 动态合成的，那么"多头"这种用于学习不同固定子空间关系的技巧就变得多余了。

DynSIHA 采用 `SPL` 模块合成 `Query`、`Key`、`Value`，将注意力机制从一个固定的信息查询系统，升级为一个**端到端可学习的、可编程的动态信息路由与处理系统**：

- **动态投影合成**：根据当前输入的语义内容，动态生成最适合的 Q、K、V 投影矩阵
- **内容感知路由**：每个 token 都能激活不同的专家组合，实现**细粒度的信息处理**
- **消除冗余设计**：不再需要预先定义固定的注意力头，系统能够**自组织**地发现所需的信息处理模式。
