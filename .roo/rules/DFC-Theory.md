# Dynamic Function Composition

`Latest update: 2025-10-03`

## 摘要

本文阐述了“动态函数合成” (Dynamic Function Composition) 的核心理念及其在 `Tiny-ONN-ARC` 模型中的演进过程。该理念旨在将神经网络的每一层从静态的变换器，升级为能够为每个输入动态合成专用计算函数的自适应系统。本文将追溯其从早期的稀疏贝叶斯线性层 (SBL) 的探索，到最终形态——基于惊奇感知路由塑造 (SARS) 的稀疏原型线性层 (SPL) 的完整理论发展路径。

## 1. 早期探索：稀疏贝叶斯线性层 (SBL) 的局限性

动态函数合成的最初构想源于对 IPWT 的反思。我们尝试通过稀疏贝叶斯线性层 (SBL) 将贝叶斯神经网络的不确定性建模能力与脉冲神经网络的稀疏激活机制相融合。然而，基于 SBL 及早期 SPL (v1-v2) 的实验揭示了两个根本性问题：

1. **梯度信号冲突 (Gradient Signal Conflict):** 多个不同的学习目标（如主任务与稀疏性约束）由同一个全局损失函数（如 SML 和 KL 散度）驱动，导致梯度方向相互矛盾，优化过程不稳定。
2. **灾难性遗忘 (Catastrophic Forgetting):** 对于需要学习离散因果规则的 ARC 任务，统一的梯度更新机制是致命的。新任务产生的梯度会轻易覆盖或“冲刷”掉为先前任务固化的知识。

这些失败使我们认识到，**Surprise 本身不应作为直接的优化目标，而是一个需要被处理和解读的信息信号**。原始梯度范数 `Si = ||∇{xi} Lmain||₂` 包含了过多的噪声和绝对尺度信息，直接用于优化会导致数值不稳定和学习目标模糊。

## 2. 核心组件：稀疏原型线性层 (SparseProtoLinear, SPL)

当前架构的基石是稀疏原型线性层 (SPL)。它将传统的线性变换解耦为三个功能正交的状态空间，这一核心设计在整个研究历程中保持不变：

- `μ` **(muweight): 计算核心**
  - **职责:** 代表系统所拥有的、可供选择的“计算工具集”。每一行都是一个专用的计算原型或“专家”。
- `p` **(protoweight): 模式匹配器**
  - **职责:** 代表系统的“感知器官”，负责将外部输入 `x` 与内部原型 `μ` 进行模式匹配，评估相似度。
- `g` **(gateparam): 激活门控**
  - **职责:** 代表系统的“行动策略”，根据感知结果（匹配度）和元学习信号，决定激活哪些计算路径（专家）。其学习机制是理论演进的关键。

## 3. 阶段一：基于启发式规则的路由 (SAPS)

我们最初的尝试深受自由能原理 (FEP) 启发，将单个 SPL 神经元视为一个实现主动推断的计算单元。这一阶段的核心是**惊奇感知原型锐化 (Surprise-Aware Prototype Sharpening, SAPS)** 及其带记忆机制的变体 `M-SAPS`。

该框架试图通过一套解耦的学习动力学来驱动系统自组织：

- `μ` 的学习由主任务损失 `L_main` 驱动。
- `p` 的学习由基于“原型漂移成本”的对比损失 `L_proto` 驱动。
- `g` 的学习由一个独立的回归损失 `L_gate` 驱动，目标是预测激活某个专家将引发的“总系统扰动”。

然而，该框架在实践中导致了灾难性的路由失败。后续分析揭示了其不可调和的理论缺陷：

1. **值域不匹配 (Domain Mismatch):** 核心路由方程 `F.relu(cos_sim - sigmoid(cost))` 错误地将两个不同数学域的变量（范围 `[-1, 1]` vs. `[0, 1]`）直接相减，创造了一个巨大的梯度死亡区。
2. **梯度信号冲突 (Gradient Signal Conflict):** 试图通过分离的损失函数和优化器来学习一个内在统一的路由决策，导致了优化目标的内在矛盾。
3. **饱和非线性 (Sigmoid Saturation):** `sigmoid` 函数的使用导致梯度消失，使模型难以从错误的激活抑制中恢复。

> **结论：** 试图将一个统一的决策过程分解为多个独立优化的启发式目标，存在内在的理论矛盾，难以形成协同的全局策略。

## 4. 阶段二：基于信息论的路由重构 (SARS)

**惊奇感知路由塑造 (Surprise-Aware Routing Shaping, SARS)** 是对早期理论的重构。它将动态路由问题重新定义为一个基于信息论的概率分布对齐问题。

### 4.1. 核心思想：双流优化与 JSD 分布对齐

SARS 的最终形态建立在两大基石之上：

1. **双优化器框架 (Dual-Optimizer Framework):** 为解决梯度信号纠缠问题，我们将优化过程严格分离为两个正交的流程：

   - **计算流 (Computation Stream):** 主任务损失 `L_main` 的梯度**仅**用于更新计算参数（如 `muweight`, `embedding`）。
   - **元学习流 (Meta-Learning Stream):** 从计算流中无损提取的原始梯度信号，用于构建元学习目标 `L_meta`。该损失的梯度**仅**用于更新路由参数（如 `protoweight`, `gateparam`）。
   - 这种架构确保了引导路由的元信号不会反向污染其赖以生成的计算梯度，保证了两个学习过程的独立性与正交性。

2. **JSD 分布对齐 (JSD Distribution Alignment):** 元学习的核心目标，是让模型自身的路由激活分布 `P`（由 `routing_logits` 导出），去拟合一个理想的专家效用分布 `Q`（由 `Goodness` 分数定义）。我们采用**詹森-香农散度 (Jensen-Shannon Divergence, JSD)** 作为度量。
   `L_meta = D_JSD( P || Q )`
   与 KL 散度相比，JSD 是对称的，且其标准实现能稳健处理非归一化输入，是衡量此类分布相似性的更优选择。

### 4.2. 关键改进：协同净效用模型 (Synergistic Net Utility Model)

早期效用模型的探索揭示了对梯度信号语义的深刻误解。一个真正完备的决策系统，必须能准确地区分收益与成本，并捕捉它们之间的协同效应。为此，我们将效用函数重构为一个基于“协同净效用”原则的全新模型。

其理论基础是：一个理想的专家，其**由前向贡献与后向任务相关性共同构成的协同收益**，必须显著超过其**为适应当前任务所需付出的参数学习成本**。

该模型由三个核心组件构成：

1. **前向贡献 (Forward Contribution, `B_contrib`)**: 定义为专家在前向传播中的**实际输出贡献**。它由经过路由权重缩放后的输出张量 `masked_output` 的 L2 范数来衡量，直接反映了专家对最终结果的“发言权”。
   `B_contrib = ||masked_output||₂`

2. **任务相关性 (Task Relevance, `B_rel`)**: 定义为任务损失对专家输出的**敏感度**。它由主损失对 `masked_output` 的梯度范数来衡量。梯度越大，说明该专家的输出对解决当前任务越关键。
   `B_rel = ||∇_{masked_output} L_main||₂`

3. **学习成本 (Learning Cost, `C_learn`)**: 定义为专家为适应当前任务所需付出的**参数扰动成本**。这直接量化了“灾难性遗忘”的风险，由主损失对计算核心 `mu_weight` 的真实参数梯度的 L2 范数来衡量。
   `C_learn = ||∇_{mu_weight} L_main||₂`

最终，这三个组件通过一个**乘性收益-加性成本**模型组合成最终的效用（`Goodness`）分数。该模型的核心创新在于**协同收益**项：

`Synergistic_Benefit = mas_normalize(mas_normalize(B_contrib) * mas_normalize(B_rel))`
`Goodness = F.relu(Synergistic_Benefit - mas_normalize(C_learn))`

这个公式的精妙之处在于，一个专家只有在**同时具备高“前向贡献”和高“任务相关性”**时，其协同收益项才会很高。如果其中任何一项接近于零，整个收益项就会被压制。这为元学习提供了一个极其稀疏且信息丰富的目标分布 `Q`，因为它只奖励那些“在正确的时间做正确的事”的精英专家，并惩罚那些需要高昂学习成本的专家。

### 4.3. 关键机制：最大绝对值缩放 (MAS)

为了给 JSD 提供数值稳定且信息无损的输入，我们引入了**最大绝对值缩放 (Max Absolute Scaling, MAS)**，它在数学上等价于 L-infinity 范数。

`x_normalized = x / (max(abs(x)) + ε)`

MAS 取代了 `softmax` 和 `sigmoid`，其核心优势在于：

- **无信息失真:** 保持原始数据的相对比例。
- **自适应无参数:** 自动根据数据范围进行缩放。
- **有界输出:** 输出范围始终在 `[-1, 1]` 内。

## 6. 元学习的本地相对性

**SARS 元学习的本质是本地化的、可微分的赫布学习 (Hebbian Learning)**。赫布定律的核心思想是“一起激活的神经元会连接在一起”。在 SARS 框架下：

- 一个专家（神经元集合）若被激活（`routing_logits` 高），并且其处理后的输出对主任务有显著贡献（`I_effective` 高），那么其对应的 `Goodness` 分数就会高。
- 元学习的目标 `L_meta` 会驱动路由分布 `P` 去对齐这个高 `Goodness` 的分布 `Q`。
- 这等价于，通过梯度下降，**强化了那些“共同激活”且表现良好的专家的路由权重**。

因此，SARS 并非在全局层面上强制执行某种抽象的稀疏性约束，而是作为一种**本地的、自组织的机制**，在每个 SPL 模块内部，动态地强化或抑制特定的计算路径。这种**本地相对性 (Local Relativity)** 确保了每个模块都能独立地、高效地学习到最适合其局部输入-输出关系的专家组合，而不会被其他模块的噪声信号所干扰。这是系统能够形成稳定、功能特化的稀疏结构的关键。

## 5. 宏观架构

### 5.1. 整体架构组件

- **MoIE (Mixture of Infinite Experts):** 将标准的 `FFN` 替换为两层 `SPL`，将其升级为一个两阶段的、内容感知的动态函数合成器。
- **DynSIHA (Dynamic Sparse Infinite-Head Attention):** 抛弃传统的多头注意力，采用 `SPL` 模块一次性合成 `Query`、`Key`、`Value`，将注意力机制升级为端到端可学习的动态信息路由系统。
- **PRC (Prototype Resident Connection):** 在传统的激活值残差连接之外，为原型网络提供了独立的残差流。这通过独立的层归一化和变换，实现了**梯度隔离**和**分层增量抽象**，保护了专家功能的分化过程。

### 5.2. Mu 残差连接 (MRC) 

理论上，更深的网络架构有利于 `Tiny-ONN-ARC` 进行**分层增量抽象 (Hierarchical Incremental Abstraction)**，这对于解决复杂的 ARC 任务至关重要。然而，实验证据（`4L` vs. `8L` 模型）揭示了一个深刻的实践悖论：随着网络深度的增加，驱动 `SARS` 元学习的梯度信号在反向传播过程中严重**衰减和失真**。

`SARS` 的核心——`Goodness` 分数——完全派生自 `L_main` 的梯度。当梯度路径过长时，到达浅层网络的信号变得微弱且充满噪声，导致元学习失效，专家无法实现有效的功能分化。这使得深层网络的理论优势在实践中无法发挥。

为了解决这一核心矛盾，我们补充了 **Mu 残差连接 (Mu Resident Connection, MRC)**。该机制将经典的残差连接思想直接注入到 `SPL` 模块的计算核心中。

其核心思想是将 `SPL` 模块的功能，从学习一个**绝对变换** `y = F(x)`，重构为学习一个**增量修正** `y = x + F(x)`。

- **形式化定义**: `output_spl = x_spl + Gating(x_spl) * μ`

`MRC` 在我们的架构中扮演了**模块内梯度高速公路**的角色：

1. **保护元学习信号**: `L_main` 对 `output_spl` 的梯度，现在可以通过 `x_spl` 这条路径，无条件、无衰减地反向传播至 `SPL` 模块的输入。这确保了无论网络多深，每个 `SPL` 模块的 `SARS` 机制都能接收到高质量、高信噪比的元学习信号。
2. **简化专家学习**: 专家 (`μ` 矩阵中的原型) 的学习任务被极大简化。它们不再需要从头构建一个完整的输出表征，而只需学会如何对输入进行最有效的“微调”或“修正”。

#### 5.2.3. 功能正交性：MRC 与传统残差连接 (TRC)

`MRC` 并非要取代位于 `Transformer` 块外部的**传统残差连接 (Traditional Residual Connection, TRC)**。两者功能正交，互为补充，共同构成了一个鲁棒的多层梯度管理体系：

- **TRC (块间)**: 保护**主任务梯度**在**整个深度网络**中的有效流动，确保端到端的监督学习。
- **MRC (模块内)**: 保护**元学习梯度**在**单个 `SPL` 模块内部**的有效流动，确保 `SARS` 路由机制的正常运作。

这个双层残差结构，是 `Tiny-ONN-ARC` 在维持深度抽象能力的同时，保证其动态自组织机制有效性的关键。

### 5.3. SPL 作为隐式级联 VAE

SPL 架构与 SARS 元学习动力学的结合，在功能上实现了一个隐式的、确定性的 **矢量量化变分自编码器 (VQ-VAE)**。

- **编码器 (Encoder):** 路由通路 `p` 和 `g` 共同构成编码器。它将输入 `x` 映射到一个稀疏的、离散的潜在代码 `z`（即路由权重），该代码指向被选中的专家。
- **码本 (Codebook):** `μ` 矩阵的每一行 `μi` 相当于码本中的一个“码字”，代表一个专用的计算函数。
- **解码器 (Decoder):** 解码过程是简单的线性组合 `output = z * μ`，即根据编码结果 `z` 从码本中加权选择码字。

将此模型扩展到整个 `Tiny-ONN-ARC` 架构，可以将其视为一个**级联 VAE (Cascaded VAE)**。

1. **第一层 VAE (嵌入层):** `ArcEmbedding` 将离散的输入 token 编码为连续的隐藏状态。
2. **后续 VAE (SPL 层):** 每一层的 `SPL` 模块（如 `DynSIHA` 和 `MoIE`）都作为一个独立的 VQ-VAE 运行，将上一层的输出作为输入，进行新一轮的编码-解码，学习更高级的抽象表示。
3. **级联与协同:** `PRC` 机制为每个 VAE 提供了连贯的上下文和记忆，使整个级联系统能够进行深度的分层信息整合。

因此，`Tiny-ONN-ARC` 的学习过程可以被理解为：

> 联合优化一个级联 VAE 系统，使其在给定数据时，能学习到最优的码本布局（所有 `μ` 矩阵）和编码策略（所有 `p` 和 `g` 参数），从而最大化整个系统的预测能力。
