# 常用资源路径

为了方便快速查找常用依赖库的文档或咨询 Deepwiki，以下是其对应的 GitHub Repository 地址：

## 核心参考

- `pytorch/pytorch`
- `LINs-lab/DynMoE`

## 标准预制件

- `huggingface/transformers`
- `huggingface/accelerate`
- `bitsandbytes-foundation/bitsandbytes`

## 其他

- `fla-org/native-sparse-attention`
- `IntelLabs/bayesian-torch`
- `rusty1s/pytorch_sparse`
- `huggingface/candle`

## 源代码文件

以下是重要的参考源代码在工作区内的路径：

- `Qwen3` 模型架构定义： `.venv\Lib\site-packages\transformers\models\qwen3\modeling_qwen3.py`
- `DynMoE`的动态 MoE：`ref\DynMoE\DeepSpeed-0.9.5\deepspeed\moe\sharded_moe.py`
- `DynMoE`的 SDL 实现：`ref\DynMoE\DeepSpeed-0.9.5\deepspeed\moe\loss.py`
- `Native Sparse Attention`的 Pytorch 实现：`ref\native-sparse-attention-pytorch\native_sparse_attention_pytorch`
