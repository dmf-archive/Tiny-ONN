# Tiny-ONN-ARC 理论备忘录

`Latest update: 2025-10-01`

## Emergent Differentiable Program Search

我们的核心假设（H₀）认为，ARC 任务中蕴含的抽象算法可以通过梯度下降在通用计算基质中自组织地涌现出来。这一涌现过程依赖于三个关键组件构成的计算基质：`DynSIHA` 和 `Proto Resident Connection` 提供了动态信息路由机制，`MoIE` 构成了自适应计算单元集合，而 `SARS` 则作为驱动专家特化的梯度信号源。这三者的协同作用创造了一个能够自动发现和学习抽象计算规则的环境。

---

## 优化动力学：Key-in-Lock 模型

ARC 任务的地形特征为"钥匙与锁孔"，损失函数不连续且崎岖，每个 (任务, 视角) 对构成独立的损失子空间，不适合梯度平均。极小值稀疏且尖锐，需要精确收敛。

为此，我们提出：

1. 严格禁止梯度平滑或平均操作，以保留梯度信号的精确性。
2. 采用单视角过拟合策略，使每个训练步骤产生的梯度信号纯净，精确引导参数找到正确的极小值。

---

## 自组织现象：B.L.O.O.M. (Blooming Layers Of Optimal Modules)

我们观察到一种名为 **B.L.O.O.M.** 的自组织现象，即专家原型的分化仅在前几层的特定模块中涌现，而深层模块暂时保持锁定状态。

这不是失败，而是模型在信息论效率极限下运行的标志。它发现解决当前任务所需的最小有效容量仅存在于浅层，并将稀缺的梯度信号集中于此。更深层的模块则作为高效的信息聚合通道，而非独立计算单元。B.L.O.O.M. 证明了我们的架构能自组织地找到最紧凑的问题解决路径。

我们推测，ARC 任务在认知上呈双阶段特征：首阶段为模式识别，此过程驱动了 B.L.O.O.M.；次阶段为抽象推理，其神经元活动理论上将趋于高度聚合与结构化。因此，B.L.O.O.M. 或可视为模型成功分化出其“感知器官”的标志

---

## Hierarchical Additive Multi-modal Embedding

为解决模型在处理变长序列时出现的长度泛化瓶颈，架构经历了从“位置解耦”到“位置即内容”的演进。

最初，问题被归结为RoPE（绝对位置编码）与 DynSIHA 中 SPL 模块的深度耦合，导致 SPL 模块退化为内容-位置混合函数合成器，无法泛化至新位置。

理论突破：空间位置是抽象推理任务内容本身的内在组成部分 (`Content ≜ (Color, Position)`)。因此，位置信息不应与内容分离后重新注入，而应在输入层即与内容融合。

最终架构为“分层加性多模态嵌入”（HAME）：

HAME 架构通过“2D 几何嵌入（由 ArcEmbedding 提供）”与“1D 序列顺序（由 RoPE 提供）”的**分层加性结合**，保证了几何信息的完整性、保护了内容处理器的职责，并保留了序列建模能力。
