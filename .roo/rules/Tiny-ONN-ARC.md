# Tiny-ONN-ARC: 项目报告与实施计划 (v2.0)

## 摘要

`Tiny-ONN-ARC` 是一个为解决 `ARC-AGI-2` 抽象推理任务而设计的专用语言模型。作为 `Tiny-ONN` 项目的一个分支，它继承了**超稀疏混合专家 (Hyper-SMoE)** 的核心思想，并针对 ARC 任务的特性进行了深度特化。本项目并非传统的程序合成，而是通过构建一个通用的**可微计算基质 (Differentiable Computational Substrate)**，让解决问题的抽象程序在梯度下降中**自组织地涌现**。模型架构基于标准的 `Qwen3` 注意力机制和 **SDL DynMoE (动态专家混合)**，训练范式依赖 **Teacher Forcing** 和 **多视角数据增强** 来驱动模型学习抽象规则。

---

## 1. 系统工作流程

整个系统的工作流程遵循一个清晰的、顺序化的数据处理与学习管道：

1. **M1: 数据表征 (Data Representation)**
    - **Tokenizer**: 使用一个极小的、针对 ARC 任务的专属词汇表，包含 0-9 的颜色 token 和必要的控制 token (`<|im_start|>`, `<|im_end|>`, `problem`, `solution` 等)。
    - **Serializer**: 将 2D 网格及其坐标信息线性化为 1D token 序列。这是模型能够理解空间关系的基础。

2. **M3: 数据加载与预处理 (Data Loading & Pre-processing)**
    - **ArcDataset**: 从 JSON 文件中读取并加载完整的任务数据，每个任务（包含其所有 `train` 和 `test` 对）作为一个样本。
    - **ArcCollator**: 作为数据加载器的核心，它接收一批原始任务数据，并负责执行“多示例上下文”拼接、D8 对称数据增强、序列化以及最终的批次填充，直接产出可供模型计算的规整张量。

3. **M2: 模型架构 (Model Architecture)**
    - **核心**: `ArcTransformer`，一个标准的 Decoder-only Transformer 骨架。
    - **创新**: 其核心计算单元是 `DynONNBlock`，它用标准的 `Qwen3` 自注意力和我们定制的 **SDL DynMoE (动态专家混合)** 分别取代了标准的注意力和前馈网络层。

4. **M6 & M4: 训练编排与范式 (Orchestration & Paradigms)**
    - **Trainer**: 作为顶层协调器，负责驱动整个训练与评估循环。
    - **StepRunners**: `Trainer` 根据配置，实例化具体的训练步骤执行器 (`TFStepRunner`)，将训练范式的具体逻辑解耦。
    - **训练循环**: `Trainer` 从 `DataLoader` 获取批次，交由 `StepRunner` 执行，然后负责梯度累积和优化器步骤。

5. **M5: 推理与评估 (Inference & Evaluation)**
    - **EvaluationStep**: 一个独立的评估逻辑单元，负责在 `torch.no_grad()` 上下文中执行完整的评估流程。
    - **Sequence Generator**: 利用 `model.generate` 进行自回归推理，生成解答序列。
    - **Grid Decoder**: `Serializer` 的逆过程，将 token 序列解码回 2D 网格。
    - **AugScore Evaluator**: 实现多视角一致性评估，为模型的最终解答提供鲁棒性评分。

6. **M6: 系统支持 (System Support)**
    - **Config**: 提供统一的、结构化的配置管理。
    - **Observer**: 负责所有训练过程中的日志记录与可视化。

---

## 2. 核心范式与理论基础

### 2.1. 方法论：涌现式可微程序搜索

我们将 ARC 视为一个“可微程序搜索”问题，但摒弃了传统的、基于预定义符号原语的显式搜索方法，因为该方法面临组合爆炸和泛化难题。

取而代之，我们采用一种“自下而上”的**涌现式 (Emergent)** 方法：

- **通用计算基质**: `ArcTransformer` (尤其是其 `DynMoE` 层) 本身被视为一个极其灵活和通用的、完全可微的计算图。注意力机制是通用的信息路由，而 `DynMoE` 则是通用的计算单元动态选择器。
- **隐式程序涌现**: 我们不预设任何高层级的操作（如 `Copy`, `Resize`）。相反，我们相信，通过端到端的梯度下降，模型能够在其权重空间中，自组织地学习到实现这些功能所必需的底层计算模式。`DynMoE` 中的每个专家，在训练的驱动下，会自发地专门化为处理某种特定模式（如颜色替换、对称性识别）的“微型程序”。

### 2.2. 核心训练范式: Teacher Forcing + 多视角增强

我们采用单一且专注的训练范式来解决 ARC 任务：

- **Teacher Forcing (TF)**:
  - **目标**: 快速学习 ARC 任务的“语法”和局部模式规则。
  - **方法**: 使用标准的自回归训练。模型被给予一个完整的“问题-答案”序列，并被要求在每个时间步预测下一个正确的 token。
  - **作用**: 此阶段计算效率高，能让模型快速掌握基础知识，并促使 MoE 专家进行功能分化。

- **多视角数据增强 (Multi-View Data Augmentation)**:
  - **目标**: 学习几何不变性，增强模型的泛化能力。
  - **方法**: 在训练过程中，对输入的 ARC 网格进行 D8 对称变换（旋转、翻转），让模型在多种视角下学习同一个任务的解决方案。
  - **作用**: 这是驱动模型从“记住模式”到“理解规则”的关键步骤。

### 2.3. AugScore 多视角一致性评估

- **动机**: 一个真正理解了抽象规则的模型，其对一个问题的解答不应因观察视角（如旋转或翻转）的改变而改变。
- **方法**:
    1. **并行生成**: 将一个测试问题进行所有 8 种 D8 对称变换，形成 8 个不同的“视角”。让模型为每个视角生成一个或多个候选解答。
    2. **逆变换与聚合**: 将所有生成的解答通过逆变换统一到原始坐标系下，形成一个候选池。
    3. **交叉评分**: 对候选池中的**每一个**候选解，我们再将其变换到所有 8 个视角，并计算模型在每个视角下生成该解的**对数概率**。
    4. **最终选择**: 将一个候选解在 8 个视角下的对数概率求和，得到其最终的 `AugScore`。分数最高的候选解被认为是模型“共识度”最高的答案。
