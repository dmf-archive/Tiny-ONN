# SPL 神经元作为马尔可夫毯：最终统一理论

`Latest update: 2025-09-27`

本文档形式化定义了 `Tiny-ONN` 项目中 `SparseProtoLinear` (SPL) 神经元的最终理论框架。该理论将单个 SPL 神经元视为一个实现了主动推断（Active Inference）的计算单元，其架构与自由能原理（Free Energy Principle, FEP）中的马尔可夫毯（Markov Blanket）概念形成了完美的数学对偶。

## 1. 核心比喻：神经元即细胞

我们将一个 SPL 神经元 `i` 类比为一个生物细胞：

- **`μᵢ` (mu_weight)**: 细胞的**内部状态**（细胞质、细胞核、细胞器）。它包含了神经元的核心计算功能和已习得的知识。
- **`pᵢ` (proto_weight) 和 `gᵢ` (gate_param)**: 共同构成**细胞膜**，即系统的**马尔可夫毯**。这个毯子将内部状态 `μᵢ` 与外部世界（输入 `x`）隔离开。
  - **`pᵢ`**: 膜上的**识别蛋白**（感官状态），负责“感知”外部世界，计算**证据流 (Evidence Flow)** `mᵢ = ReLU(cos(x, pᵢ))`。`ReLU`确保了只有语义匹配（夹角<90 度）的信号才能被考虑。
  - **`gᵢ`**: **离子通道**（行动状态），负责调节细胞膜的通透性。它根据历史经验计算出一个**先验置信度 (Prior Confidence)** `cᵢ = Sigmoid(<x, gᵢ>)`。
- **`aᵢ` (activation)**: **最终信息流 (Final Information Flow)** `aᵢ = mᵢ * cᵢ`。它是在证据流 `mᵢ` 通过了先验置信度 `cᵢ` 的门控后，最终穿透细胞膜的信号强度。

## 2. 理论基础：重要性加权的自由能最小化

根据 FEP，神经元（细胞）的唯一目标是最小化其**变分自由能 `F`**。在我们的框架中，这等价于最小化由**输出重要性 (`I_o`)** 加权的**总系统扰动 (`S_total`)**。

`F ≈ Cost_effective = I_o * S_total`

- **输出重要性 (`I_o`)**: `I_o = ||∇_x L_main||`。衡量了该神经元所处理的输入 `x` 对最终任务的**因果影响力**。一个扰动只有在重要的时候才值得关注。

- **总系统扰动 (`S_total`)**: 分解为内部扰动和边界扰动。
  1. **内部惊奇度 (`S_μ`)**: `S_μ = ||∇_μ L_main||`。激活行为对内部状态 `μ` 造成的扰动。
  2. **边界惊奇度 (`S_p`)**: `S_p = ||∇_p L_proto||`。马尔可夫毯（细胞膜）为了适应外部世界而需要付出的“**原型漂移成本**”。

## 3. 学习动力学：解耦但统一的 1F3B 流程

为了最小化加权自由能，系统演化出了三个功能正交但目标统一的学习过程，通过一个计算上精确的**1F3B (一次前向，三次反向)** 流程实现。

### 3.1. `μ` (内部状态) 的学习

- **目标**: 完成最终任务 (`L_main`)，同时保护内部稳态（避免灾难性遗忘）。
- **驱动力**: `L_main` 的梯度 `∇_μ L_main`。
- **机制**: `_apply_mu_suppression` 通过动态阈值抑制大部分梯度，保护已固化的知识。

### 3.2. `proto` (感知状态) 的学习

- **目标**: 塑造一个高效的感知空间，使其能够以最小的**内部扰动**来识别重要的输入。
- **成本函数**: `Cost_proto = I_o * S_μ`。
- **损失函数 (SAPS)**: `L_proto = Σ aᵢ * signs(Cost_protoᵢ)`。这是一个有全局上下文的赫布式/反赫布式学习规则。
- **动力学**: 根据 `Cost_proto` 的高低，来**吸引**或**排斥**原型 `pᵢ`，从而优化其识别能力。

### 3.3. `gate` (行动状态) 的学习

- **目标**: 作为一个完备的**成本预测器**，准确预测一次激活将引发的**总系统扰动**。
- **成本函数**: `Cost_gate = I_o * (S_μ + S_p)`。
- **损失函数**: `L_gate = Σ aᵢ * Cost_gateᵢ`。
- **动力学**: 梯度下降会调整 `gᵢ`，使其输出的 `Sigmoid(<x,gᵢ>)` 与预期的总成本 `Cost_gate` 成反比，从而做出有远见的、趋利避害的门控决策。

### 3.4. 1F3B 计算流程

1. **B1 (获取基础信号)**: 对 `main_loss` 进行一次反向传播，同时计算 `mu_grads` (→`S_μ`) 和 `sbl_input_grads` (→`I_o`)。
2. **B2 (计算原型漂移成本)**: 基于 `Cost_proto` 构建并反向传播 `L_proto`，得到 `proto_grads`，其范数即为 `S_p`。
3. **B3 (学习预测总成本)**: 基于 `Cost_gate` 构建并反向传播 `L_gate`，得到 `gate_grads` 用于更新。
