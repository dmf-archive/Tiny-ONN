import re
import os
import subprocess
import tempfile
from pathlib import Path

def get_class_definition(file_content: str, class_name: str) -> str:
    pattern = re.compile(
        f"(@[^\n]+\n)*class {class_name}[^:]*:\n((?:    .*\n|\n)+)", re.MULTILINE
    )
    match = pattern.search(file_content)
    if not match:
        raise ValueError(f"Class '{class_name}' not found in the provided content.")
    return match.group(0)

def main():
    project_root = Path(__file__).parent.parent
    exp_arc_dir = project_root / "exp" / "arc"
    notebook_file = project_root / "notebook" / "train_kaggle.py"
    notebook_output_path = project_root / "notebook" / "train_kaggle.ipynb"

    print("Starting Kaggle Notebook build process...")

    # 1. Define Topological Order of source files for consolidation
    source_files_order = [
        "tokenizer.py",
        "model.py",
        "data.py",
        "train.py",
    ]

    # 2. Extract replacement components from the target notebook file
    with open(notebook_file, "r", encoding="utf-8") as f:
        notebook_content = f.read()
    
    kaggle_config = get_class_definition(notebook_content, "TrainConfig")
    kaggle_dataconfig = get_class_definition(notebook_content, "DataConfig")
    kaggle_modelconfig = get_class_definition(notebook_content, "ModelConfig")
    
    kaggle_dataset = get_class_definition(notebook_content, "InMemoryArcDataset")
    kaggle_observer = get_class_definition(notebook_content, "MinimalObserver")
    kaggle_dynamics = get_class_definition(notebook_content, "LearningDynamics")
    kaggle_trainer = get_class_definition(notebook_content, "KaggleTrainer")

    # 3. Consolidate source files
    full_script_content = ""
    for filename in source_files_order:
        with open(exp_arc_dir / filename, "r", encoding="utf-8") as f:
            full_script_content += f.read() + "\n\n"

    # 4. Perform Transformations
    print("Transforming consolidated script...")

    # 4.1 Remove all local relative imports
    full_script_content = re.sub(r"from \.[\w\.]+ import .*", "", full_script_content)

    # 4.2 Remove original definitions that will be replaced
    classes_to_remove = [
        "ModelConfig", "DataConfig", "TrainConfig", 
        "InMemoryArcDataset", "Observer", "LearningDynamics", "Trainer", "EvaluationStep", "SimpleEvaluator",
        "GridDeserializer"
    ]
    for class_name in classes_to_remove:
        full_script_content = re.sub(
            f"class {class_name}[^:]*:\n(?:(?:    .*\n|\n)+)", "", full_script_content, flags=re.MULTILINE
        )
    
    # 4.3 Remove original main execution block
    full_script_content = re.sub(r"def main\(\):.*", "", full_script_content, flags=re.DOTALL)
    full_script_content = re.sub(r'if __name__ == "__main__":.*', "", full_script_content, flags=re.DOTALL)
    
    # 4.4 Construct the final script
    header = """
# =============================================================================
# This script is auto-generated by scripts/build_kaggle_script.py
# Do not edit this file directly.
# =============================================================================
import os
import random
import time
from pathlib import Path
from typing import Any, Dict, List, Tuple
from dataclasses import dataclass, field
import json

import torch
import torch.nn as nn
import torch.nn.functional as F
from rich.console import Console
from torch.utils.data import DataLoader, Dataset
from torch.nn.utils.rnn import pad_sequence
from torch.nn.attention import SDPBackend, sdpa_kernel
import math

try:
    import torch_xla.core.xla_model as xm
except ImportError:
    pass
"""
    
    final_script = (
        header.strip() + "\n\n# %% [markdown]\n# # Configuration\n\n# %%" +
        f"\n{kaggle_modelconfig}\n\n{kaggle_dataconfig}\n\n{kaggle_config}" +
        "\n\n# %% [markdown]\n# # Core Code Definitions\n\n# %%" +
        f"\n{full_script_content.strip()}" +
        f"\n\n{kaggle_dataset}\n\n{kaggle_observer}\n\n{kaggle_dynamics}\n\n{kaggle_trainer}"
    )

    # 4.5 Inject xm.mark_step() for TPU best practices
    final_script = final_script.replace(
        "xm.optimizer_step(self.optimizer_route)",
        "xm.optimizer_step(self.optimizer_route)\n            xm.mark_step()"
    )

    # 4.6 Add final execution block
    execution_block = """
# %% [markdown]
# # Execution

# %%
def main():
    print("ðŸš€ Starting training process...")
    config = TrainConfig()
    torch.manual_seed(config.seed)
    random.seed(config.seed)

    try:
        import torch_xla.core.xla_model as xm
        IS_TPU = True
    except ImportError:
        IS_TPU = False
    
    if IS_TPU:
        config.device = xm.xla_device()
    
    trainer = KaggleTrainer(config)
    trainer.train()
    
    print("âœ… Training process finished.")


if __name__ == "__main__":
    main()
"""
    final_script += "\n\n" + execution_block.strip()

    with tempfile.NamedTemporaryFile(mode="w+", delete=False, suffix=".py", encoding="utf-8") as temp_f:
        temp_f.write(final_script)
        temp_script_path = temp_f.name

    print("Generated temporary script, converting to notebook with jupytext...")

    try:
        result = subprocess.run(
            [
                "uv", "run", "jupytext", "--to", "notebook",
                "--output", str(notebook_output_path),
                temp_script_path
            ],
            check=True,
            capture_output=True,
            text=True
        )
        print(result.stdout)
        if result.stderr:
            print("Jupytext stderr:")
            print(result.stderr)
        print(f"âœ… Successfully created Kaggle Notebook at: {notebook_output_path}")
    except subprocess.CalledProcessError as e:
        print(f"ðŸ”¥ Jupytext conversion failed with exit code {e.returncode}")
        print(e.stdout)
        print(e.stderr)
    finally:
        os.remove(temp_script_path)


if __name__ == "__main__":
    main()